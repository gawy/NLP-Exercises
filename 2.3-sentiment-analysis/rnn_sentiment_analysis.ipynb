{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Part 2\n",
    "\n",
    "_Natural Langauge Processing Nanodegree Program_\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Switching gears - RNNs\n",
    "\n",
    "We just saw how the task of sentiment analysis can be solved via a traditional machine learning approach: BoW + a nonlinear classifier. We now switch gears and use Recurrent Neural Networks, and in particular LSTMs, to perform sentiment analysis in Keras. Conveniently, Keras has a built-in [IMDb movie reviews dataset](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification) that we can use, with the same vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 2.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d9/ea9816aea31beeadccd03f1f8b625ecf8f645bd66744484d162d84803ce5/PyYAML-5.3.tar.gz (268kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 8.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from keras) (1.15.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from keras) (1.11.0)\n",
      "Collecting h5py (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/0d/de4d889991536b2d6c8b15958e0eb70efaf1d89c87c175725bde46f8bd0f/h5py-2.10.0-cp35-cp35m-macosx_10_6_intel.whl (2.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.9MB 3.5MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from keras) (1.0.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 8.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 16.0MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/andrew/Library/Caches/pip/wheels/e4/76/4d/a95b8dd7b452b69e8ed4f68b69e1b55e12c9c9624dd962b191\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, h5py, keras-applications, keras-preprocessing, keras\n",
      "Successfully installed h5py-2.10.0 keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 pyyaml-5.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/61/7d1c4cff2da973aea6b04a8b0a64231155c3163372e073e2d189ef1e3dda/tensorflow-2.1.0-cp35-cp35m-macosx_10_11_x86_64.whl (120.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 120.8MB 354kB/s ta 0:00:011   23% |███████▌                        | 28.3MB 3.8MB/s eta 0:00:25    42% |█████████████▌                  | 51.1MB 5.4MB/s eta 0:00:14    42% |█████████████▊                  | 51.9MB 3.4MB/s eta 0:00:21    74% |███████████████████████▊        | 89.7MB 4.4MB/s eta 0:00:08\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K    100% |████████████████████████████████| 450kB 2.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from tensorflow) (1.0.8)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 5.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 6.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting six>=1.12.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.8.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/f8/cf301f76f0f58732b62a0b45017e63e4014f1dfdffc171c83091b48ff30b/protobuf-3.11.3-cp35-cp35m-macosx_10_9_intel.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 3.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/5f/0055ed980b6ada5d56b3dd2e1bddd50689ba8cb65c08009ea1792a720e86/grpcio-1.27.1-cp35-cp35m-macosx_10_7_intel.whl (4.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.7MB 3.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.8MB 2.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from tensorflow) (0.31.1)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 6.4MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/49/c75be5bb62a53eeee87ef1b4a6decdd0dac2d0a0ba3408fcc309dea6a060/scipy-1.4.1-cp35-cp35m-macosx_10_6_intel.whl (28.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 28.3MB 1.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting numpy<2.0,>=1.16.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/f5/6749649c00c6fd811c57f6b85e9755651dc843d8be3831e67172928a7339/numpy-1.18.1-cp35-cp35m-macosx_10_6_intel.whl (14.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 14.8MB 1.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting gast==0.2.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: h5py in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from protobuf>=3.8.0->tensorflow) (40.2.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/6d/7aae38a9022f982cf8167775c7fc299f203417b698c27080ce09060bba07/google_auth-1.11.0-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 5.5MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/16/c5a68ef8c62406b3bbd8f49199bbae56feb390746a284c4cf036c687465f/Markdown-3.2-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 218kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/a5/d6f8a6e71f15364d35678a4ec8a0186f980b3bd2545f40ad51dd26a87fb1/Werkzeug-1.0.0-py2.py3-none-any.whl (298kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 3.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2018.8.24)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    100% |████████████████████████████████| 163kB 2.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 2.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 5.6MB/s ta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: absl-py, wrapt, opt-einsum, termcolor, gast\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/andrew/Library/Caches/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/andrew/Library/Caches/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Running setup.py bdist_wheel for opt-einsum ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/andrew/Library/Caches/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/andrew/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/andrew/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built absl-py wrapt opt-einsum termcolor gast\n",
      "\u001b[31mtensorboard 2.1.0 has requirement setuptools>=41.0.0, but you'll have setuptools 40.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-auth 1.11.0 has requirement setuptools>=40.3.0, but you'll have setuptools 40.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, six, absl-py, wrapt, numpy, opt-einsum, protobuf, astor, grpcio, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, werkzeug, tensorboard, google-pasta, scipy, termcolor, gast, tensorflow\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "  Found existing installation: numpy 1.15.2\n",
      "    Uninstalling numpy-1.15.2:\n",
      "      Successfully uninstalled numpy-1.15.2\n",
      "  Found existing installation: scipy 1.0.0\n",
      "    Uninstalling scipy-1.0.0:\n",
      "      Successfully uninstalled scipy-1.0.0\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.27.1 markdown-3.2 numpy-1.18.1 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 six-1.14.0 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 werkzeug-1.0.0 wrapt-1.11.2\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 19s 1us/step\n",
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb  # import the built-in imdb dataset in Keras\n",
    "\n",
    "# Set the vocabulary size\n",
    "vocabulary_size = 5000\n",
    "\n",
    "# Load in training and test data (note the difference in convention compared to scikit-learn)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size)\n",
    "print(\"Loaded dataset with {} training samples, {} test samples\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Review ---\n",
      "[1, 4, 2, 716, 4, 65, 7, 4, 689, 4367, 2, 2343, 4804, 2, 2, 2, 2, 2315, 2, 2, 2, 2, 4, 2, 628, 2, 37, 9, 150, 4, 2, 4069, 11, 2909, 4, 2, 847, 313, 6, 176, 2, 9, 2, 138, 9, 4434, 19, 4, 96, 183, 26, 4, 192, 15, 27, 2, 799, 2, 2, 588, 84, 11, 4, 3231, 152, 339, 2, 42, 4869, 2, 2, 345, 4804, 2, 142, 43, 218, 208, 54, 29, 853, 659, 46, 4, 882, 183, 80, 115, 30, 4, 172, 174, 10, 10, 1001, 398, 1001, 1055, 526, 34, 3717, 2, 2, 2, 17, 4, 2, 1094, 871, 64, 85, 22, 2030, 1109, 38, 230, 9, 4, 4324, 2, 251, 2, 1034, 195, 301, 14, 16, 31, 7, 4, 2, 8, 783, 2, 33, 4, 2945, 103, 465, 2, 42, 845, 45, 446, 11, 1895, 19, 184, 76, 32, 4, 2, 207, 110, 13, 197, 4, 2, 16, 601, 964, 2152, 595, 13, 258, 4, 1730, 66, 338, 55, 2, 4, 550, 728, 65, 1196, 8, 1839, 61, 1546, 42, 2, 61, 602, 120, 45, 2, 6, 320, 786, 99, 196, 2, 786, 2, 4, 225, 4, 373, 1009, 33, 4, 130, 63, 69, 72, 1104, 46, 1292, 225, 14, 66, 194, 2, 1703, 56, 8, 803, 1004, 6, 2, 155, 11, 4, 2, 3231, 45, 853, 2029, 8, 30, 6, 117, 430, 19, 6, 2, 9, 15, 66, 424, 8, 2337, 178, 9, 15, 66, 424, 8, 1465, 178, 9, 15, 66, 142, 15, 9, 424, 8, 28, 178, 662, 44, 12, 17, 4, 130, 898, 1686, 9, 6, 2, 267, 185, 430, 4, 118, 2, 277, 15, 4, 1188, 100, 216, 56, 19, 4, 357, 114, 2, 367, 45, 115, 93, 788, 121, 4, 2, 79, 32, 68, 278, 39, 8, 818, 162, 4165, 237, 600, 7, 98, 306, 8, 157, 549, 628, 11, 6, 2, 13, 824, 15, 4104, 76, 42, 138, 36, 774, 77, 1059, 159, 150, 4, 229, 497, 8, 1493, 11, 175, 251, 453, 19, 2, 189, 12, 43, 127, 6, 394, 292, 7, 2, 4, 107, 8, 4, 2826, 15, 1082, 1251, 9, 906, 42, 1134, 6, 66, 78, 22, 15, 13, 244, 2519, 8, 135, 233, 52, 44, 10, 10, 466, 112, 398, 526, 34, 4, 1572, 4413, 2, 1094, 225, 57, 599, 133, 225, 6, 227, 7, 541, 4323, 6, 171, 139, 7, 539, 2, 56, 11, 6, 3231, 21, 164, 25, 426, 81, 33, 344, 624, 19, 6, 4617, 7, 2, 2, 6, 2, 4, 22, 9, 1082, 629, 237, 45, 188, 6, 55, 655, 707, 2, 956, 225, 1456, 841, 42, 1310, 225, 6, 2493, 1467, 2, 2828, 21, 4, 2, 9, 364, 23, 4, 2228, 2407, 225, 24, 76, 133, 18, 4, 189, 2293, 10, 10, 814, 11, 2, 11, 2642, 14, 47, 15, 682, 364, 352, 168, 44, 12, 45, 24, 913, 93, 21, 247, 2441, 4, 116, 34, 35, 1859, 8, 72, 177, 9, 164, 8, 901, 344, 44, 13, 191, 135, 13, 126, 421, 233, 18, 259, 10, 10, 4, 2, 2, 4, 2, 3074, 7, 112, 199, 753, 357, 39, 63, 12, 115, 2, 763, 8, 15, 35, 3282, 1523, 65, 57, 599, 6, 1916, 277, 1730, 37, 25, 92, 202, 6, 2, 44, 25, 28, 6, 22, 15, 122, 24, 4171, 72, 33, 32]\n",
      "--- Label ---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Inspect a sample review and its label\n",
    "print(\"--- Review ---\")\n",
    "print(X_train[7])\n",
    "print(\"--- Label ---\")\n",
    "print(y_train[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the label is an integer (0 for negative, 1 for positive), and the review itself is stored as a sequence of integers. These are word IDs that have been preassigned to individual words. To map them back to the original words, you can use the dictionary returned by `imdb.get_word_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 1us/step\n",
      "--- Review (with words) ---\n",
      "['the', 'of', 'and', 'local', 'of', 'their', 'br', 'of', 'attention', 'widow', 'and', 'captures', 'parties', 'and', 'and', 'and', 'and', 'excitement', 'and', 'and', 'and', 'and', 'of', 'and', 'english', 'and', 'like', 'it', 'years', 'of', 'and', 'unintentional', 'this', 'hitchcock', 'of', 'and', 'learn', 'everyone', 'is', 'quite', 'and', 'it', 'and', 'such', 'it', 'bonus', 'film', 'of', 'too', 'seems', 'he', 'of', 'enough', 'for', 'be', 'and', 'editing', 'and', 'and', 'please', 'great', 'this', 'of', 'shoots', 'thing', '3', 'and', \"it's\", 'mentioning', 'and', 'and', 'given', 'parties', 'and', 'back', 'out', 'interesting', 'times', 'no', 'all', 'average', 'talking', 'some', 'of', 'nor', 'seems', 'into', 'best', 'at', 'of', 'every', 'cast', 'i', 'i', 'inside', 'keep', 'inside', 'large', 'viewer', 'who', 'obscure', 'and', 'and', 'and', 'movie', 'of', 'and', 'entirely', \"you've\", 'see', 'because', 'you', 'deals', 'successful', 'her', 'anything', 'it', 'of', 'dedicated', 'and', 'hard', 'and', 'further', \"that's\", 'takes', 'as', 'with', 'by', 'br', 'of', 'and', 'in', 'minute', 'and', 'they', 'of', 'westerns', 'watch', 'seemed', 'and', \"it's\", 'lee', 'if', 'oh', 'this', 'japan', 'film', 'around', 'get', 'an', 'of', 'and', 'always', 'life', 'was', 'between', 'of', 'and', 'with', 'group', 'rate', 'code', \"film's\", 'was', 'although', 'of', 'arts', 'had', 'death', 'time', 'and', 'of', 'anyway', 'romantic', 'their', 'won', 'in', 'kevin', 'only', 'flying', \"it's\", 'and', 'only', 'cut', 'show', 'if', 'and', 'is', 'star', 'stay', 'movies', 'both', 'and', 'stay', 'and', 'of', 'music', 'of', 'tell', 'missing', 'they', 'of', 'here', 'really', 'me', 'we', 'value', 'some', 'silent', 'music', 'as', 'had', 'thought', 'and', 'realized', 'she', 'in', 'sorry', 'reasons', 'is', 'and', '10', 'this', 'of', 'and', 'shoots', 'if', 'average', 'remembered', 'in', 'at', 'is', 'over', 'worse', 'film', 'is', 'and', 'it', 'for', 'had', 'absolutely', 'in', 'naive', 'want', 'it', 'for', 'had', 'absolutely', 'in', 'j', 'want', 'it', 'for', 'had', 'back', 'for', 'it', 'absolutely', 'in', 'one', 'want', 'shots', 'has', 'that', 'movie', 'of', 'here', 'write', 'whatsoever', 'it', 'is', 'and', 'set', 'got', 'worse', 'of', 'where', 'and', 'once', 'for', 'of', 'accent', 'after', 'saw', 'she', 'film', 'of', 'rest', 'little', 'and', 'camera', 'if', 'best', 'way', 'elements', 'know', 'of', 'and', 'also', 'an', 'were', 'sense', 'or', 'in', 'realistic', 'actually', 'satan', \"he's\", 'score', 'br', 'any', 'himself', 'in', 'another', 'type', 'english', 'this', 'is', 'and', 'was', 'tom', 'for', 'dating', 'get', \"it's\", 'such', 'from', 'fantastic', 'will', 'pace', 'new', 'years', 'of', 'guy', 'game', 'in', 'murders', 'this', 'us', 'hard', 'lives', 'film', 'and', 'fact', 'that', 'out', 'end', 'is', 'getting', 'together', 'br', 'and', 'of', 'seen', 'in', 'of', 'jail', 'for', 'sees', 'utterly', 'it', 'meet', \"it's\", 'depth', 'is', 'had', 'do', 'you', 'for', 'was', 'rather', 'convince', 'in', 'why', 'last', 'very', 'has', 'i', 'i', 'throughout', 'never', 'keep', 'viewer', 'who', 'of', 'becoming', 'switch', 'and', 'entirely', 'music', 'even', 'interest', 'scene', 'music', 'is', 'far', 'br', 'voice', 'riveting', 'is', 'again', 'something', 'br', 'decent', 'and', 'she', 'this', 'is', 'shoots', 'not', 'director', 'have', 'against', 'people', 'they', 'line', 'cinematography', 'film', 'is', 'couples', 'br', 'and', 'and', 'is', 'and', 'of', 'you', 'it', 'sees', 'hero', \"he's\", 'if', \"can't\", 'is', 'time', 'husband', 'silly', 'and', 'result', 'music', 'image', 'sequences', \"it's\", 'chase', 'music', 'is', 'veteran', 'include', 'and', 'freeman', 'not', 'of', 'and', 'it', 'along', 'are', 'of', 'hearing', 'cutting', 'music', 'his', 'get', 'scene', 'but', 'of', 'fact', 'correct', 'i', 'i', 'means', 'this', 'and', 'this', 'blockbuster', 'as', 'there', 'for', 'disappointed', 'along', 'wrong', 'few', 'has', 'that', 'if', 'his', 'weird', 'way', 'not', 'girl', 'display', 'of', 'love', 'who', 'so', 'friendship', 'in', 'we', 'down', 'it', 'director', 'in', 'situation', 'line', 'has', 'was', 'big', 'why', 'was', 'your', 'supposed', 'last', 'but', 'especially', 'i', 'i', 'of', 'and', 'and', 'of', 'and', 'internet', 'br', 'never', 'give', 'theme', 'rest', 'or', 'really', 'that', 'best', 'and', 'release', 'in', 'for', 'so', 'multi', 'random', 'their', 'even', 'interest', 'is', 'judge', 'once', 'arts', 'like', 'have', 'then', 'own', 'is', 'and', 'has', 'have', 'one', 'is', 'you', 'for', 'off', 'his', 'dutch', 'we', 'they', 'an']\n",
      "--- Label ---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Map word IDs back to words\n",
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print(\"--- Review (with words) ---\")\n",
    "print([id2word.get(i, \" \") for i in X_train[7]])\n",
    "print(\"--- Label ---\")\n",
    "print(y_train[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(max([len(x) for x in X_train]))\n",
    "print(min([len(x) for x in X_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13a111c18>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctr = list(chain.from_iterable(X_train))\n",
    "# ctr.values()\n",
    "plt.hist(ctr, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cnt = Counter()\n",
    "neg_cnt = Counter()\n",
    "for review,lbl in zip(X_train, y_train):\n",
    "    if lbl == 1:\n",
    "        pos_cnt.update(review)\n",
    "    else:\n",
    "        neg_cnt.update(review)\n",
    "        \n",
    "vocab = set(pos_cnt.keys()) | set(neg_cnt.keys())\n",
    "pos_neg_ratios = Counter()\n",
    "for w in vocab:\n",
    "    pos_neg_ratios[w] = math.log(pos_cnt.get(w, 1) / neg_cnt.get(w, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 0.0,\n",
       "         2: 0.13097635521151332,\n",
       "         4: 0.05851473289100667,\n",
       "         5: 0.1875223646162327,\n",
       "         6: 0.05271092536866767,\n",
       "         7: 0.107792444593422,\n",
       "         8: -0.03298557074379423,\n",
       "         9: 0.13369613192495283,\n",
       "         10: -0.06679554358812878,\n",
       "         11: 0.1377180527819303,\n",
       "         12: -0.00829775309195313,\n",
       "         13: -0.11810135493330337,\n",
       "         14: -0.15382883184672416,\n",
       "         15: -0.03923870195974696,\n",
       "         16: -0.1820552806640362,\n",
       "         17: 0.2433140610518594,\n",
       "         18: 0.022060215674009984,\n",
       "         19: 0.10744198061172544,\n",
       "         20: -0.2703894190257195,\n",
       "         21: -0.04499044881583364,\n",
       "         22: 0.08379371900175688,\n",
       "         23: -0.010764114695864115,\n",
       "         24: -0.13624433853309867,\n",
       "         25: -0.0279162620703494,\n",
       "         26: 0.012574507231922149,\n",
       "         27: 0.3494928277819276,\n",
       "         28: -0.18490066743895578,\n",
       "         29: 0.19278843834064094,\n",
       "         30: -0.1576658642029832,\n",
       "         31: 0.03598623131977237,\n",
       "         32: -0.008433231627565443,\n",
       "         33: -0.08879782639712896,\n",
       "         34: 0.12875471081558001,\n",
       "         35: 0.09497335710283615,\n",
       "         36: -0.259452225992469,\n",
       "         37: 0.13487080335409415,\n",
       "         38: -0.22419286935382748,\n",
       "         39: 0.10177606092077802,\n",
       "         40: -0.21810598088157349,\n",
       "         41: 0.27520684495974007,\n",
       "         42: -0.2844409987648044,\n",
       "         43: -0.39622944085707096,\n",
       "         44: -0.08605848489022447,\n",
       "         45: -0.0022153568204619617,\n",
       "         46: -0.10048230659530394,\n",
       "         47: 0.18900616127741904,\n",
       "         48: -0.26818313735421395,\n",
       "         49: -0.10949120121572278,\n",
       "         50: -0.2593402442662239,\n",
       "         51: -0.06765234650224296,\n",
       "         52: 0.040535350765098184,\n",
       "         53: 0.11158552464367062,\n",
       "         54: 0.1035138480692379,\n",
       "         55: 0.3655589749230471,\n",
       "         56: -0.09861834535282085,\n",
       "         57: -0.5772115498258023,\n",
       "         58: 0.04700439442857258,\n",
       "         59: 0.2184517107601841,\n",
       "         60: -0.43752019376169116,\n",
       "         61: 0.07656636190038288,\n",
       "         62: -0.25733491606248904,\n",
       "         63: 0.0809344418893735,\n",
       "         64: -0.27755503206116855,\n",
       "         65: 0.2590919128935133,\n",
       "         66: -0.1341705744935198,\n",
       "         67: 0.09955859304171835,\n",
       "         68: 0.1454740128075852,\n",
       "         69: -0.17676788148770975,\n",
       "         70: -0.00035971223409452554,\n",
       "         71: -0.227443017374209,\n",
       "         72: -0.08345932109327107,\n",
       "         73: 0.4103999083940125,\n",
       "         74: -0.09019114162586495,\n",
       "         75: 0.07179242538707771,\n",
       "         76: -0.07956644289416745,\n",
       "         77: -0.19638626398902592,\n",
       "         78: -1.3582138959791228,\n",
       "         79: -0.16413923771076416,\n",
       "         80: 0.26810155904070265,\n",
       "         81: -0.2828443800125295,\n",
       "         82: 0.43046412914338705,\n",
       "         83: -0.005268947425595717,\n",
       "         84: -0.07210329390134394,\n",
       "         85: 0.11931747634184471,\n",
       "         86: 0.09967391508153955,\n",
       "         87: 0.888440635881829,\n",
       "         88: -0.1965614371617146,\n",
       "         89: -0.10381354087439583,\n",
       "         90: 0.26252392598541296,\n",
       "         91: 0.21581901220415436,\n",
       "         92: -0.4441029008135784,\n",
       "         93: -0.17179514380696714,\n",
       "         94: 0.23785376514136036,\n",
       "         95: -0.3482716587947954,\n",
       "         96: 0.012224176168879334,\n",
       "         97: -0.3581600402125306,\n",
       "         98: -0.09097177820572676,\n",
       "         99: -0.1321274510855144,\n",
       "         100: -0.36250879042504347,\n",
       "         101: -0.4390927307889699,\n",
       "         102: -0.12726353590879178,\n",
       "         103: -0.010740116335842934,\n",
       "         104: 0.0027412297867186984,\n",
       "         105: -0.01615910426610719,\n",
       "         106: -0.036440698194357676,\n",
       "         107: 0.1643988817098411,\n",
       "         108: 0.21521662061893698,\n",
       "         109: 0.012830252087160675,\n",
       "         110: 0.044638232822709414,\n",
       "         111: 0.2592358650868696,\n",
       "         112: -0.052707534935331514,\n",
       "         113: 0.544486182549796,\n",
       "         114: -0.5367183595382305,\n",
       "         115: -0.011728529506362748,\n",
       "         116: -0.5100846085412715,\n",
       "         117: 0.07505466860042703,\n",
       "         118: 0.724223127520468,\n",
       "         119: 0.7034904791667458,\n",
       "         120: -0.09337792873517141,\n",
       "         121: -0.0047460933892556805,\n",
       "         122: -0.22759087232344377,\n",
       "         123: 0.17982467659536747,\n",
       "         124: -0.16214770471690956,\n",
       "         125: -0.3695694818224751,\n",
       "         126: -0.17785165987420884,\n",
       "         127: 0.06750200277994564,\n",
       "         128: -0.34382499115062337,\n",
       "         129: -0.2762815484197451,\n",
       "         130: -0.09223122421603362,\n",
       "         131: 0.3800199483293531,\n",
       "         132: 0.3258269648789317,\n",
       "         133: -0.07210986159289887,\n",
       "         134: -0.011074310299093665,\n",
       "         135: -0.2108744828346054,\n",
       "         136: -0.09580994777960047,\n",
       "         137: 0.18149374217714476,\n",
       "         138: -0.6276325734493188,\n",
       "         139: -0.13811041433668567,\n",
       "         140: -0.10929849761129182,\n",
       "         141: 0.01752722570896032,\n",
       "         142: -0.3216189675179573,\n",
       "         143: -0.060795534858736774,\n",
       "         144: -0.3102819043690219,\n",
       "         145: 0.04880984940255499,\n",
       "         146: -0.4260953028747502,\n",
       "         147: 0.16833531481921474,\n",
       "         148: 0.11642526219592308,\n",
       "         149: -0.2933909366721011,\n",
       "         150: 0.05748208275437523,\n",
       "         151: 0.16867220799357655,\n",
       "         152: -0.2969557092371101,\n",
       "         153: 0.45120648942823777,\n",
       "         154: 0.041802440156831835,\n",
       "         155: -0.5477565627932793,\n",
       "         156: -0.16997623243233842,\n",
       "         157: 0.14536875369916696,\n",
       "         158: 0.14393009984542116,\n",
       "         159: 0.01250305706578576,\n",
       "         160: -0.08249232475416693,\n",
       "         161: -0.4600682773097419,\n",
       "         162: 0.28144307215164777,\n",
       "         163: -0.17632068152081729,\n",
       "         164: -0.8390627815755611,\n",
       "         165: -0.31458210121870833,\n",
       "         166: 0.2745029956637482,\n",
       "         167: -0.16244088274773208,\n",
       "         168: -0.16806785170524116,\n",
       "         169: 0.19885967712619873,\n",
       "         170: -0.262364264467491,\n",
       "         171: -0.11749318898324329,\n",
       "         172: -0.05235763649659201,\n",
       "         173: 0.08199276301241826,\n",
       "         174: 0.15531144606322062,\n",
       "         175: -0.0347204687037378,\n",
       "         176: 0.09588782495372661,\n",
       "         177: 0.22951375098477414,\n",
       "         178: 0.2829073232957695,\n",
       "         179: 0.29423947299793995,\n",
       "         180: -0.1367110455419023,\n",
       "         181: -0.3172845505808107,\n",
       "         182: 0.5659094777057196,\n",
       "         183: 0.0032626456348163694,\n",
       "         184: -0.3111449634663843,\n",
       "         185: 0.5814466847897864,\n",
       "         186: -0.2370810591579914,\n",
       "         187: -0.14858488218218624,\n",
       "         188: -0.17792324765264608,\n",
       "         189: -0.396110502940944,\n",
       "         190: 0.031102309093955765,\n",
       "         191: -0.3694823902286585,\n",
       "         192: -0.0886440304135151,\n",
       "         193: -0.05307950589890872,\n",
       "         194: 0.0870113769896297,\n",
       "         195: -0.3148207800510789,\n",
       "         196: -0.038354497776225877,\n",
       "         197: -0.09275078375968686,\n",
       "         198: -0.3750083746492773,\n",
       "         199: 0.6637655449916526,\n",
       "         200: 0.38338915640896465,\n",
       "         201: 0.5341926484200415,\n",
       "         202: -0.1615836115021242,\n",
       "         203: 0.3532107372410634,\n",
       "         204: -0.35241208570778376,\n",
       "         205: 0.41294457453945704,\n",
       "         206: 0.13713528872873446,\n",
       "         207: -0.16313763057093097,\n",
       "         208: 0.039956889108826915,\n",
       "         209: 0.0459217505856397,\n",
       "         210: 0.595965685719905,\n",
       "         211: 0.2657031657330057,\n",
       "         212: 0.1544392384788061,\n",
       "         213: -0.2954981624109073,\n",
       "         214: -0.14005370021822033,\n",
       "         215: 0.14157433142398293,\n",
       "         216: -0.001883831012373524,\n",
       "         217: 0.47511350239800615,\n",
       "         218: -0.32988865016286084,\n",
       "         219: 0.13793146741688678,\n",
       "         220: -0.004462870014898317,\n",
       "         221: -0.10833509870563533,\n",
       "         222: -0.6015054000597923,\n",
       "         223: 0.5528988245909914,\n",
       "         224: 0.04784364256540105,\n",
       "         225: -0.4710579256006416,\n",
       "         226: -0.29982182700239146,\n",
       "         227: 0.30298458987861815,\n",
       "         228: 0.2784866053586806,\n",
       "         229: -0.7714106722364241,\n",
       "         230: -0.17579564555899366,\n",
       "         231: -0.2944107738727719,\n",
       "         232: -0.5987943967119478,\n",
       "         233: -0.5560145836433912,\n",
       "         234: -0.9428441398266708,\n",
       "         235: 0.16277777173487745,\n",
       "         236: 0.10817650365535758,\n",
       "         237: 0.0895298168888254,\n",
       "         238: -0.2707938544232592,\n",
       "         239: 0.6905585174524348,\n",
       "         240: -0.10032602981347824,\n",
       "         241: -0.7312067423842903,\n",
       "         242: -0.032374396659016,\n",
       "         243: -0.21375988757216516,\n",
       "         244: -0.17795733641735775,\n",
       "         245: -0.11803921600875157,\n",
       "         246: 0.2628795291961397,\n",
       "         247: -0.0395076983755121,\n",
       "         248: 0.019034249622513835,\n",
       "         249: -2.293342511627113,\n",
       "         250: -0.045562619678565494,\n",
       "         251: 0.35811534750070123,\n",
       "         252: -0.13422947293210352,\n",
       "         253: 0.5197942937487511,\n",
       "         254: -0.06080672142542387,\n",
       "         255: 0.07259422196978779,\n",
       "         256: 0.43485524220706123,\n",
       "         257: 0.5398733092062215,\n",
       "         258: 0.030317129515237257,\n",
       "         259: -0.14729020879595026,\n",
       "         260: -0.012578782206860073,\n",
       "         261: 0.37009796427087305,\n",
       "         262: 0.48901267837860624,\n",
       "         263: 0.3180227895044532,\n",
       "         264: -0.2928090937036138,\n",
       "         265: 0.16812654270549846,\n",
       "         266: 0.028987536873252187,\n",
       "         267: -0.30698132995629784,\n",
       "         268: 0.09531017980432493,\n",
       "         269: -0.4081659875352966,\n",
       "         270: 0.08515780834030677,\n",
       "         271: -0.05734576747047327,\n",
       "         272: -0.5452926264038686,\n",
       "         273: 0.09332329260190732,\n",
       "         274: -0.11620574826313487,\n",
       "         275: 0.540041184810793,\n",
       "         276: -0.1220512440319577,\n",
       "         277: 0.0,\n",
       "         278: -0.8244939260098194,\n",
       "         279: -0.4043973023473342,\n",
       "         280: 0.2237242152229087,\n",
       "         281: -0.24759654537613016,\n",
       "         282: -0.665483789013935,\n",
       "         283: 0.5589385105644606,\n",
       "         284: 0.03457561350974073,\n",
       "         285: -0.05889147361862193,\n",
       "         286: -0.5876518122284604,\n",
       "         287: 0.5200956785622772,\n",
       "         288: 0.2578747453545892,\n",
       "         289: 0.0975740469515567,\n",
       "         290: 0.14612942820053787,\n",
       "         291: 0.20298078089639413,\n",
       "         292: 0.6008139317558976,\n",
       "         293: -0.15497136103868756,\n",
       "         294: -0.5478890411428782,\n",
       "         295: 0.28403718427177355,\n",
       "         296: -0.042940407234028956,\n",
       "         297: 0.2164748391191717,\n",
       "         298: 0.2437334133378175,\n",
       "         299: 0.5007026161345421,\n",
       "         300: -0.754524594014122,\n",
       "         301: -0.24160561415394513,\n",
       "         302: -0.4531567700399481,\n",
       "         303: 0.42106961123156156,\n",
       "         304: 0.26801627789883753,\n",
       "         305: -0.731043551298824,\n",
       "         306: -0.10963568734612665,\n",
       "         307: 0.9850575891212473,\n",
       "         308: 0.4517696761498507,\n",
       "         309: 0.2806607095526247,\n",
       "         310: 0.16565166916256985,\n",
       "         311: -0.1476557446767101,\n",
       "         312: 0.02519965355631515,\n",
       "         313: 0.0233983533730015,\n",
       "         314: -0.007497692105800813,\n",
       "         315: 0.111800963978836,\n",
       "         316: 0.1945852911163627,\n",
       "         317: -0.20048029180582572,\n",
       "         318: -0.08676234199892673,\n",
       "         319: 0.1164325965585121,\n",
       "         320: -0.5790192411808224,\n",
       "         321: 1.4637564221999353,\n",
       "         322: 0.24526689365105953,\n",
       "         323: 0.18805223150293962,\n",
       "         324: -0.19701979595078423,\n",
       "         325: 0.5711944583959688,\n",
       "         326: -0.5888559386616777,\n",
       "         327: 0.25372147321327065,\n",
       "         328: -0.047032179538533954,\n",
       "         329: -0.1323248772961816,\n",
       "         330: 0.006085211475545644,\n",
       "         331: -0.3025411868555307,\n",
       "         332: -0.20571991016695618,\n",
       "         333: 0.0592614640367275,\n",
       "         334: -0.4110697789553349,\n",
       "         335: -0.35994415343914055,\n",
       "         336: 0.6668502282694834,\n",
       "         337: 0.11058071965973586,\n",
       "         338: -1.2691121064968973,\n",
       "         339: 0.09077959063006177,\n",
       "         340: -0.4824090261032233,\n",
       "         341: 0.07111749223561362,\n",
       "         342: -0.6836081575131864,\n",
       "         343: -0.0628200123798705,\n",
       "         344: 0.19764301148838817,\n",
       "         345: -0.5493140044075967,\n",
       "         346: 0.1614669745179424,\n",
       "         347: -0.18133487689150957,\n",
       "         348: -0.11701645838618796,\n",
       "         349: 0.2807222215167211,\n",
       "         350: 0.2997725792616216,\n",
       "         351: -0.3458268417884332,\n",
       "         352: -0.5843881909430073,\n",
       "         353: -0.29758156252554885,\n",
       "         354: 0.7505433895642609,\n",
       "         355: -0.5557238911310366,\n",
       "         356: 0.6357072748110303,\n",
       "         357: -1.4926333136148913,\n",
       "         358: 0.5424991312838892,\n",
       "         359: -0.11320277508082795,\n",
       "         360: -0.2679626683249796,\n",
       "         361: -0.08111051343436652,\n",
       "         362: -0.14949830648353774,\n",
       "         363: 0.219135529916671,\n",
       "         364: -0.6681666975915037,\n",
       "         365: -0.23652252154443512,\n",
       "         366: 0.1511882310283021,\n",
       "         367: 0.22973753919350556,\n",
       "         368: 0.2404291876012353,\n",
       "         369: 0.19246552122296576,\n",
       "         370: -0.4012248190692789,\n",
       "         371: 0.3370623812237639,\n",
       "         372: -0.11219147659414708,\n",
       "         373: -2.2305937185108378,\n",
       "         374: -0.413232137445824,\n",
       "         375: -0.0011661808901825075,\n",
       "         376: -0.23680640179132753,\n",
       "         377: 0.29145760465248577,\n",
       "         378: -0.09429831845541285,\n",
       "         379: -1.656826534678244,\n",
       "         380: -0.2475738688211103,\n",
       "         381: 0.10222669924165494,\n",
       "         382: 0.09984533496971612,\n",
       "         383: -0.49657360105878917,\n",
       "         384: -0.6780156056910362,\n",
       "         385: 0.13305050778717184,\n",
       "         386: 0.4009707185203251,\n",
       "         387: -0.28172863164928225,\n",
       "         388: 0.2467314688386857,\n",
       "         389: 1.5658440144685963,\n",
       "         390: 0.47000362924573563,\n",
       "         391: -0.034066554563606195,\n",
       "         392: 0.3988677738519586,\n",
       "         393: 0.01586366397316748,\n",
       "         394: -1.7358008155800104,\n",
       "         395: 0.1240090747358993,\n",
       "         396: -0.1166249579357558,\n",
       "         397: -0.24256163717131135,\n",
       "         398: -0.05199190671789179,\n",
       "         399: -0.31104079872940915,\n",
       "         400: 0.42999020895621537,\n",
       "         401: 0.07643042198762275,\n",
       "         402: 0.38046380590274714,\n",
       "         403: -0.29061033223086924,\n",
       "         404: 1.253569745465308,\n",
       "         405: 0.2664746962949538,\n",
       "         406: 0.519236102274587,\n",
       "         407: 0.6638583604919077,\n",
       "         408: 0.6356655082720548,\n",
       "         409: 0.3210555812682875,\n",
       "         410: -0.05891588353659473,\n",
       "         411: -0.3717269684763143,\n",
       "         412: 0.4178943413408556,\n",
       "         413: 0.3790698240412096,\n",
       "         414: -0.45274367646091374,\n",
       "         415: -0.13387903733513323,\n",
       "         416: 0.07681067650160701,\n",
       "         417: 0.13562417329765314,\n",
       "         418: -0.3010130640095266,\n",
       "         419: -0.32819200580551544,\n",
       "         420: -0.1061900470202017,\n",
       "         421: -0.18256168166003825,\n",
       "         422: -0.09455858262501267,\n",
       "         423: 0.4413508245588684,\n",
       "         424: -1.2822838287922989,\n",
       "         425: -0.2120206348954629,\n",
       "         426: -0.8228250038684779,\n",
       "         427: -0.2696352900047074,\n",
       "         428: 0.06226638872600057,\n",
       "         429: 0.20792255730385442,\n",
       "         430: 0.2494206513526931,\n",
       "         431: 0.2485543782279188,\n",
       "         432: -0.28093467634261793,\n",
       "         433: -1.7402258191128723,\n",
       "         434: 0.26538815549256806,\n",
       "         435: -0.17830951530399386,\n",
       "         436: -0.3838364903813864,\n",
       "         437: -2.639793435647761,\n",
       "         438: 0.3894647667617233,\n",
       "         439: -0.6022219042491792,\n",
       "         440: 0.1430013362024102,\n",
       "         441: 0.3691603431777291,\n",
       "         442: -0.059698500933570146,\n",
       "         443: 0.31410100379594985,\n",
       "         444: 0.3071948866753626,\n",
       "         445: -0.17233299891044876,\n",
       "         446: -0.2218848979070136,\n",
       "         447: 1.1592944098376925,\n",
       "         448: 0.18977564605708408,\n",
       "         449: -1.0818051703517284,\n",
       "         450: 0.20921045701028565,\n",
       "         451: 0.2477179489502519,\n",
       "         452: 0.3233557017187414,\n",
       "         453: 0.4888217010995475,\n",
       "         454: 0.10883405233765032,\n",
       "         455: -0.5273232164279624,\n",
       "         456: 0.5815072094172758,\n",
       "         457: -0.21307689705599522,\n",
       "         458: -0.1595270368636387,\n",
       "         459: -0.43087482363353274,\n",
       "         460: -0.20652808517708973,\n",
       "         461: 0.11316408980008884,\n",
       "         462: -0.29617830028086656,\n",
       "         463: -0.16925296167911896,\n",
       "         464: 0.32397207385698146,\n",
       "         465: 0.4170612099755362,\n",
       "         466: 0.13647516866853593,\n",
       "         467: 0.04249723722387814,\n",
       "         468: -0.5269012493103142,\n",
       "         469: 0.3488289693101185,\n",
       "         470: -0.7850370919594722,\n",
       "         471: -0.0960146532395886,\n",
       "         472: -0.7912539632410552,\n",
       "         473: -0.3636899920429312,\n",
       "         474: -0.23887082880216817,\n",
       "         475: 0.09730932369446788,\n",
       "         476: 0.25226853578578173,\n",
       "         477: 0.22756307236124013,\n",
       "         478: 0.6092522844721339,\n",
       "         479: 0.47787768567664146,\n",
       "         480: 1.3996152050955513,\n",
       "         481: -0.2518929646001956,\n",
       "         482: -0.7404728032633014,\n",
       "         483: 0.9846841728021717,\n",
       "         484: -0.3527712304582591,\n",
       "         485: -0.07524653541004338,\n",
       "         486: 0.24527446836998057,\n",
       "         487: -0.3958588863027245,\n",
       "         488: 0.41896579532706696,\n",
       "         489: -0.15295750464692318,\n",
       "         490: 0.026296952290462118,\n",
       "         491: 0.07123754134077522,\n",
       "         492: 0.4022361740789928,\n",
       "         493: -0.3468709438421116,\n",
       "         494: 0.082408688479624,\n",
       "         495: 0.6767725456881553,\n",
       "         496: -0.02504043195968744,\n",
       "         497: -0.4886814141292426,\n",
       "         498: 0.30147539458411676,\n",
       "         499: 0.2583221654383109,\n",
       "         500: 0.3066597306375129,\n",
       "         501: 0.35744536000149174,\n",
       "         502: 0.3109065254831516,\n",
       "         503: -0.368472779262594,\n",
       "         504: 0.18845385809601847,\n",
       "         505: 0.1553878444042074,\n",
       "         506: 0.1556376689488365,\n",
       "         507: -0.47130486560370727,\n",
       "         508: -0.09622803209455377,\n",
       "         509: -0.6181566737094575,\n",
       "         510: 0.8722847455805464,\n",
       "         511: -0.32734732884421236,\n",
       "         512: 0.37258727261129165,\n",
       "         513: 0.3079897360932537,\n",
       "         514: 1.2664258189724857,\n",
       "         515: 0.2981833622724443,\n",
       "         516: -0.377581628758046,\n",
       "         517: -0.21392689620928568,\n",
       "         518: 0.4577466146182055,\n",
       "         519: -0.401358326155511,\n",
       "         520: -0.06411398281661201,\n",
       "         521: -0.18867654867633193,\n",
       "         522: 0.41925843024050014,\n",
       "         523: 0.11270192251619399,\n",
       "         524: 0.07287992336866066,\n",
       "         525: -0.19264658019210315,\n",
       "         526: 0.11307714461897085,\n",
       "         527: -1.9083470474796649,\n",
       "         528: -0.04341249293531343,\n",
       "         529: 0.2370876249952834,\n",
       "         530: 1.2313717785140506,\n",
       "         531: 0.16663134105086747,\n",
       "         532: -0.07774183368018699,\n",
       "         533: 0.05406722127027579,\n",
       "         534: -0.6590744839240653,\n",
       "         535: -0.01869213301215252,\n",
       "         536: -0.45317796682684197,\n",
       "         537: 0.3666046904010433,\n",
       "         538: -0.29416103854949005,\n",
       "         539: -0.2046530399165772,\n",
       "         540: -0.5223068061399471,\n",
       "         541: -0.4998062285163801,\n",
       "         542: -0.8683773761782575,\n",
       "         543: 0.6595956463887124,\n",
       "         544: 0.12024912815157694,\n",
       "         545: 1.1456244706651642,\n",
       "         546: -0.3131806492203765,\n",
       "         547: 0.16147076131376403,\n",
       "         548: 0.02282803255620084,\n",
       "         549: -0.6118442332741212,\n",
       "         550: -0.325539847143319,\n",
       "         551: 0.12260232209233228,\n",
       "         552: 0.05358424613410626,\n",
       "         553: -0.28506905816124806,\n",
       "         554: -0.325422400434628,\n",
       "         555: 0.49933124434025555,\n",
       "         556: -0.406965483483399,\n",
       "         557: -0.019802627296179754,\n",
       "         558: -0.5451202185832161,\n",
       "         559: 0.4988206776691673,\n",
       "         560: -0.10650272023660333,\n",
       "         561: 0.20359895524123955,\n",
       "         562: 0.06911841288439216,\n",
       "         563: 0.01637889208403968,\n",
       "         564: -0.1716405473736206,\n",
       "         565: 0.8477319823823002,\n",
       "         566: -0.2251948340847672,\n",
       "         567: -0.053174762487256125,\n",
       "         568: 0.09952959534703307,\n",
       "         569: 0.2866039052314355,\n",
       "         570: -0.27958486221916157,\n",
       "         571: -0.3708595789306889,\n",
       "         572: 0.15242802651581214,\n",
       "         573: 0.3202582428863936,\n",
       "         574: -0.11163997114266942,\n",
       "         575: -0.201421728167374,\n",
       "         576: -0.10299084630250786,\n",
       "         577: -0.009389740349839032,\n",
       "         578: -0.4843703749007746,\n",
       "         579: 0.2706907072440448,\n",
       "         580: 0.3284141752914506,\n",
       "         581: 0.30584937640722987,\n",
       "         582: 0.1135433774035804,\n",
       "         583: -0.6606813793103682,\n",
       "         584: -0.06441620445953965,\n",
       "         585: 0.42681823257873336,\n",
       "         586: -0.6492618654347889,\n",
       "         587: 0.3888573717085039,\n",
       "         588: 0.4373149339952635,\n",
       "         589: -0.8459363897888825,\n",
       "         590: -0.17217983671541565,\n",
       "         591: -0.6419996693930043,\n",
       "         592: 0.525625587706871,\n",
       "         593: -0.19465651495190595,\n",
       "         594: -0.524207192461822,\n",
       "         595: -1.8376390749787488,\n",
       "         596: 0.3620848124779393,\n",
       "         597: 0.342117279006798,\n",
       "         598: 0.16884139523726202,\n",
       "         599: -0.9732920858739819,\n",
       "         600: -0.7048091203077883,\n",
       "         601: -0.4845286714755286,\n",
       "         602: -0.17341677845099493,\n",
       "         603: 0.4233663184374045,\n",
       "         604: -0.2055992416633002,\n",
       "         605: -0.4323945199867958,\n",
       "         606: 0.752511789609551,\n",
       "         607: -1.0015974938156906,\n",
       "         608: -0.8709844249065712,\n",
       "         609: -0.5908683314395271,\n",
       "         610: -0.6783320947748046,\n",
       "         611: 0.1918210801851687,\n",
       "         612: 0.27259182672819093,\n",
       "         613: 0.3822082459438971,\n",
       "         614: -0.21684573472721974,\n",
       "         615: -0.7661278839661816,\n",
       "         616: -1.3613554127726384,\n",
       "         617: 0.2671715380359426,\n",
       "         618: -0.09262148988039656,\n",
       "         619: -0.004024150299725491,\n",
       "         620: -0.30475637597362876,\n",
       "         621: 0.5303067593378132,\n",
       "         622: -0.024292692569044587,\n",
       "         623: 0.016227536621756754,\n",
       "         624: -0.2776317365982795,\n",
       "         625: 0.35076068322978254,\n",
       "         626: 0.3843583726871492,\n",
       "         627: 0.3532207090706448,\n",
       "         628: 0.5195071758508176,\n",
       "         629: -0.513539329637587,\n",
       "         630: -0.0733526280585898,\n",
       "         631: 0.1942887901166487,\n",
       "         632: -0.07955263170195365,\n",
       "         633: -0.15730625202606813,\n",
       "         634: -0.3420725312721446,\n",
       "         635: 0.47333141933841016,\n",
       "         636: -0.053400776727115296,\n",
       "         637: -0.4106065076085831,\n",
       "         638: 0.012371291802546829,\n",
       "         639: 1.1346772235889055,\n",
       "         640: -0.5053311044483499,\n",
       "         641: 0.43995128417933366,\n",
       "         642: 0.5108256237659907,\n",
       "         643: 0.3003748992501999,\n",
       "         644: 0.23762640198458038,\n",
       "         645: -0.2653043621384877,\n",
       "         646: -0.02284626885116973,\n",
       "         647: -1.5187413509632883,\n",
       "         648: -0.3375404225871219,\n",
       "         649: 0.7482358523786856,\n",
       "         650: 0.3829922522561057,\n",
       "         651: -0.029108084158070657,\n",
       "         652: 0.23253329166404882,\n",
       "         653: 0.32611315130826296,\n",
       "         654: 0.49691719371985876,\n",
       "         655: -0.15123096972392353,\n",
       "         656: 0.05667833701843823,\n",
       "         657: 0.08408311721054144,\n",
       "         658: 0.245958229080381,\n",
       "         659: 0.5040802356264591,\n",
       "         660: -0.6475058996037413,\n",
       "         661: 0.06344622173896226,\n",
       "         662: -0.38346686071304514,\n",
       "         663: 0.15906469462968728,\n",
       "         664: 0.41429129073643645,\n",
       "         665: -0.36155990030401064,\n",
       "         666: -0.21266227384662686,\n",
       "         667: 0.15119063819878142,\n",
       "         668: -0.30010459245033816,\n",
       "         669: -0.051074929936415395,\n",
       "         670: 0.42591935611371623,\n",
       "         671: 0.18583649890139908,\n",
       "         672: 0.8513711857748395,\n",
       "         673: 0.06231876439925819,\n",
       "         674: 0.41443377809092485,\n",
       "         675: -0.3324139392232081,\n",
       "         676: -0.1989292931936152,\n",
       "         677: -0.27573600143338034,\n",
       "         678: -0.09943389698818693,\n",
       "         679: -0.2411620568168881,\n",
       "         680: 0.09737416402517637,\n",
       "         681: -0.4063680427067566,\n",
       "         682: 0.4636633473511525,\n",
       "         683: -0.46752881801266644,\n",
       "         684: -0.8322833406868977,\n",
       "         685: -0.49455565417947167,\n",
       "         686: -0.384583732055809,\n",
       "         687: 0.43301505987639494,\n",
       "         688: 0.14768257217076583,\n",
       "         689: 0.11232918497391972,\n",
       "         690: 0.3406318190981567,\n",
       "         691: -0.5379979984030974,\n",
       "         692: 0.2529965144638909,\n",
       "         693: 0.9475432753782596,\n",
       "         694: 0.19618235758618982,\n",
       "         695: -0.1896655310497131,\n",
       "         696: 0.7453915795974649,\n",
       "         697: 0.05792264773270451,\n",
       "         698: 0.3582996396657343,\n",
       "         699: 0.28963329258304266,\n",
       "         700: 0.32158362412746233,\n",
       "         701: -0.3675151584915973,\n",
       "         702: -0.16592774701827828,\n",
       "         703: -0.15241967714472843,\n",
       "         704: 0.3376267489680379,\n",
       "         705: 0.6562920881707909,\n",
       "         706: -1.2319363629545828,\n",
       "         707: 0.16215211406295937,\n",
       "         708: 0.32914902023528264,\n",
       "         709: 0.921809074612602,\n",
       "         710: -0.7356344543992616,\n",
       "         711: 0.23074815069942906,\n",
       "         712: 0.08799359885427636,\n",
       "         713: -0.44327679585127294,\n",
       "         714: 0.13595563623602894,\n",
       "         715: -0.0272125635248847,\n",
       "         716: 0.5272045158500304,\n",
       "         717: 0.4273187093947852,\n",
       "         718: 0.6222912437926007,\n",
       "         719: 0.05480823649499495,\n",
       "         720: 0.23242675361775897,\n",
       "         721: 0.12241330404054572,\n",
       "         722: 0.1641507631618416,\n",
       "         723: 0.6966133885364316,\n",
       "         724: -0.26810669206034016,\n",
       "         725: 0.1095389658813014,\n",
       "         726: 0.08884343857076718,\n",
       "         727: -1.0264397642637786,\n",
       "         728: 0.8579273310969127,\n",
       "         729: 0.30756616946163956,\n",
       "         730: -0.34130316389087856,\n",
       "         731: 0.7037292898904823,\n",
       "         732: 0.19308592338111313,\n",
       "         733: -0.5190198076550268,\n",
       "         734: -0.25191484859314983,\n",
       "         735: 0.9911470203511481,\n",
       "         736: 0.175806875772761,\n",
       "         737: 0.7561743371129005,\n",
       "         738: 0.10234846518783472,\n",
       "         739: -0.16446004948611959,\n",
       "         740: -0.21725960815523498,\n",
       "         741: 0.29462172556232136,\n",
       "         742: 0.26341745045214976,\n",
       "         743: -0.05484091569958613,\n",
       "         744: 0.2981314883261222,\n",
       "         745: 0.34967374847974886,\n",
       "         746: 0.18805223150293962,\n",
       "         747: -0.1743533871447778,\n",
       "         748: 0.6390799592896695,\n",
       "         749: 0.24175383117087748,\n",
       "         750: -0.299045831102096,\n",
       "         751: -0.034066554563606195,\n",
       "         752: 0.16664374407472485,\n",
       "         753: -1.5831973397815833,\n",
       "         754: 0.002453988961566787,\n",
       "         755: -0.5615444288418283,\n",
       "         756: 0.35249957252825176,\n",
       "         757: -0.12300497963753508,\n",
       "         758: 0.06644509940815276,\n",
       "         759: 0.14539705590102361,\n",
       "         760: -0.3614682425110121,\n",
       "         761: 0.14842000511827322,\n",
       "         762: -0.9740495660263475,\n",
       "         763: -0.18820792199056538,\n",
       "         764: -0.03708706866233596,\n",
       "         765: 0.39311927228586513,\n",
       "         766: 0.37868698902677156,\n",
       "         767: 0.32328336218587855,\n",
       "         768: 0.3827133511247483,\n",
       "         769: -0.31899151010433746,\n",
       "         770: 0.45665121561528643,\n",
       "         771: 0.47040939106911567,\n",
       "         772: -0.16537587994791952,\n",
       "         773: 0.19562145474229037,\n",
       "         774: 0.18323940908418349,\n",
       "         775: -0.015037877364540559,\n",
       "         776: 0.6650817276616615,\n",
       "         777: 1.5117638297004306,\n",
       "         778: 0.5114965395912243,\n",
       "         779: -0.21010112090103036,\n",
       "         780: 0.33127966761958566,\n",
       "         781: -0.7255618392442271,\n",
       "         782: 0.5461794076390866,\n",
       "         783: -0.3622322290035988,\n",
       "         784: -0.25809411526628484,\n",
       "         785: 0.5716159319385331,\n",
       "         786: -0.4502010019495559,\n",
       "         787: 0.7744298139968023,\n",
       "         788: 0.002547772078798783,\n",
       "         789: -0.40546510810816444,\n",
       "         790: 0.790310929013593,\n",
       "         791: 0.21280457351903045,\n",
       "         792: 0.22831746340217518,\n",
       "         793: 0.5067356385144656,\n",
       "         794: 0.272778666949206,\n",
       "         795: -0.025708356710206923,\n",
       "         796: -0.07715908054661809,\n",
       "         797: 0.30122629755953817,\n",
       "         798: -1.5757955960158656,\n",
       "         799: 0.251642135968584,\n",
       "         800: 0.202236866494896,\n",
       "         801: 0.23885525071897304,\n",
       "         802: -0.554537056856407,\n",
       "         803: -0.456535412194869,\n",
       "         804: 0.5226026909570105,\n",
       "         805: -0.6989894561841737,\n",
       "         806: -1.0120442723596508,\n",
       "         807: -0.6064712052169278,\n",
       "         808: -0.02604313853601998,\n",
       "         809: 0.020834086902842053,\n",
       "         810: 0.29453924217791805,\n",
       "         811: 0.894431938061656,\n",
       "         812: 0.36747898929207806,\n",
       "         813: 0.34905101882807305,\n",
       "         814: 0.060306606230991135,\n",
       "         815: -0.8447994206116048,\n",
       "         816: 0.3716744273234442,\n",
       "         817: 0.03942691997945792,\n",
       "         818: 0.03953083875663522,\n",
       "         819: -0.2946025152963547,\n",
       "         820: -0.3333026618599338,\n",
       "         821: 0.8166608909253137,\n",
       "         822: -0.0556434915687032,\n",
       "         823: 0.4946109576264267,\n",
       "         824: -0.053062844975211555,\n",
       "         825: 0.010610179112015469,\n",
       "         826: 0.3492519632676119,\n",
       "         827: 0.3360157198362929,\n",
       "         828: -0.2954642128938359,\n",
       "         829: 0.5065612249795332,\n",
       "         830: -0.6081997877911671,\n",
       "         831: 0.02139118998131756,\n",
       "         832: 0.2315926058007373,\n",
       "         833: 1.0299837822790134,\n",
       "         834: -0.1616413515564159,\n",
       "         835: -1.9914081921945133,\n",
       "         836: 0.043367229115129864,\n",
       "         837: 0.5036053757925035,\n",
       "         838: -0.2592441371312474,\n",
       "         839: 0.5014290963699081,\n",
       "         840: 0.04348511193973889,\n",
       "         841: 0.7095409903356217,\n",
       "         842: 0.0,\n",
       "         843: 0.4054651081081644,\n",
       "         844: 0.1044905721492862,\n",
       "         845: -0.5284472251158101,\n",
       "         846: 0.3757486357796875,\n",
       "         847: -0.05242579733984974,\n",
       "         848: -0.08004270767353637,\n",
       "         849: 0.3355225689335056,\n",
       "         850: 0.2119004597400294,\n",
       "         851: -0.7056734403791256,\n",
       "         852: 0.42866800518782827,\n",
       "         853: 0.18384944097200775,\n",
       "         854: 0.2262734443231375,\n",
       "         855: 0.3235749955123875,\n",
       "         856: -0.2722408879634031,\n",
       "         857: -0.31785150285582864,\n",
       "         858: -0.2325627732307014,\n",
       "         859: 0.00836824967051658,\n",
       "         860: 0.33264264840811497,\n",
       "         861: 0.028013036227673888,\n",
       "         862: -2.2192034840549946,\n",
       "         863: -0.7591988734560805,\n",
       "         864: -0.7851907180147533,\n",
       "         865: -0.7831436343930285,\n",
       "         866: 0.27456713037395286,\n",
       "         867: 0.5974400966027616,\n",
       "         868: 0.3529136127817342,\n",
       "         869: -0.4325734268662425,\n",
       "         870: -0.5463412567267265,\n",
       "         871: 0.16729147338831654,\n",
       "         872: -0.3818791091022852,\n",
       "         873: -0.2282586519809802,\n",
       "         874: -0.05129329438755058,\n",
       "         875: 0.1859836064004692,\n",
       "         876: 0.6209289727481461,\n",
       "         877: 0.3566749439387324,\n",
       "         878: 0.23999424166606545,\n",
       "         879: -0.2633825944943916,\n",
       "         880: -0.5308571102003704,\n",
       "         881: -0.011527505171067383,\n",
       "         882: 0.2733660384785748,\n",
       "         883: 0.4907786918207,\n",
       "         884: 0.014514042884254012,\n",
       "         885: -0.34747785045781504,\n",
       "         886: -0.15505443045361508,\n",
       "         887: -0.29793857261897005,\n",
       "         888: -0.0849705599547771,\n",
       "         889: 0.1941560144409574,\n",
       "         890: 0.2628838799637238,\n",
       "         891: -0.31527002897060996,\n",
       "         892: 0.697581777627811,\n",
       "         893: -0.12442061461099826,\n",
       "         894: -1.3496602279401102,\n",
       "         895: -0.23515170094260635,\n",
       "         896: 0.02976410190645386,\n",
       "         897: 1.7189076208420597,\n",
       "         898: -0.4079495814358264,\n",
       "         899: -0.48942171510283705,\n",
       "         900: -0.4391131422263971,\n",
       "         901: -0.7496593908232877,\n",
       "         902: -0.37813421439119305,\n",
       "         903: -0.6088400740999513,\n",
       "         904: 0.3025880915374084,\n",
       "         905: 0.33338422593263634,\n",
       "         906: 0.8631255289309088,\n",
       "         907: 0.0030165935394257273,\n",
       "         908: 0.3070659392728295,\n",
       "         909: 0.33543650374768086,\n",
       "         910: 0.39791790247278147,\n",
       "         911: 0.02417036092781297,\n",
       "         912: 0.08464264315407904,\n",
       "         913: -1.762114752643058,\n",
       "         914: 0.24017973846677756,\n",
       "         915: -0.13636827395972234,\n",
       "         916: -0.2156579770615464,\n",
       "         917: 0.024243611609992853,\n",
       "         918: -0.29918153574868056,\n",
       "         919: -0.2231435513142097,\n",
       "         920: 0.06394872460027351,\n",
       "         921: 0.7414880074942278,\n",
       "         922: 0.4054651081081644,\n",
       "         923: -0.01834913866819654,\n",
       "         924: 0.07047325665738569,\n",
       "         925: 0.47099914948723715,\n",
       "         926: 0.7185233980533199,\n",
       "         927: -0.5379542911542434,\n",
       "         928: 0.1879553745122107,\n",
       "         929: -0.3354173842027255,\n",
       "         930: -0.2849902807860695,\n",
       "         931: -0.16653768909269268,\n",
       "         932: -0.08647359800382683,\n",
       "         933: 0.534803622472651,\n",
       "         934: -0.3157763533478182,\n",
       "         935: -0.08376988306545882,\n",
       "         936: 1.0760008422815628,\n",
       "         937: 0.29673190797169885,\n",
       "         938: 0.3476455372193381,\n",
       "         939: 0.6561059088795962,\n",
       "         940: -0.31039999631143783,\n",
       "         941: 0.4563567154045537,\n",
       "         942: -0.3370071390142825,\n",
       "         943: -0.44069379999190816,\n",
       "         944: 0.25766617651151535,\n",
       "         945: -0.028170876966696335,\n",
       "         946: -0.05948545328618,\n",
       "         947: -1.682688374173693,\n",
       "         948: 0.06899287148695142,\n",
       "         949: 0.160469048356331,\n",
       "         950: 1.2039728043259361,\n",
       "         951: 0.21465693743689096,\n",
       "         952: -0.14197026127038723,\n",
       "         953: -0.2858421455297738,\n",
       "         954: -0.5745414381520983,\n",
       "         955: 1.092303119474845,\n",
       "         956: 0.2738505933033191,\n",
       "         957: -0.012658396871923465,\n",
       "         958: 0.35552043159190744,\n",
       "         959: -0.2424505507459583,\n",
       "         960: 0.012698583337127343,\n",
       "         961: 0.7363193524251541,\n",
       "         962: 0.06679748092351576,\n",
       "         963: -0.028618805305652677,\n",
       "         964: -0.8149520544441488,\n",
       "         965: 0.6457449416653614,\n",
       "         966: -0.34740130715340317,\n",
       "         967: 0.08311490671050659,\n",
       "         968: -0.14723023698268448,\n",
       "         969: -0.7856705494570908,\n",
       "         970: 0.4202008067619173,\n",
       "         971: 0.2390743733864041,\n",
       "         972: -0.07720874983197008,\n",
       "         973: -0.038589997269868975,\n",
       "         974: -0.05476408540997488,\n",
       "         975: -1.2321436812926323,\n",
       "         976: 1.3075134832667763,\n",
       "         977: -0.1681369218019982,\n",
       "         978: 0.14866027422082273,\n",
       "         979: 0.11086259281180968,\n",
       "         980: -0.19606542416502326,\n",
       "         981: -0.21581751122213683,\n",
       "         982: -0.23269191618290427,\n",
       "         983: -0.4615290022547633,\n",
       "         984: 0.5238977053333435,\n",
       "         985: 0.410914712875729,\n",
       "         986: -0.5212969236332861,\n",
       "         987: 0.06221318450157275,\n",
       "         988: 0.3714250618681733,\n",
       "         989: -0.052471051737453596,\n",
       "         990: -0.4027291282892896,\n",
       "         991: 0.9710510630300908,\n",
       "         992: -0.4941658785248153,\n",
       "         993: 0.4109596274258051,\n",
       "         994: 0.40409242429619224,\n",
       "         995: -1.432231456306916,\n",
       "         996: -1.34755353280346,\n",
       "         997: -0.013201511858535842,\n",
       "         998: 0.34101511780151295,\n",
       "         999: 0.6289275878256515,\n",
       "         1000: 0.3051752298992982,\n",
       "         1001: 0.040005334613699206,\n",
       "         ...})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13939a358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(pos_neg_ratios.values(), 100)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_cut = {w for w in vocab if abs(pos_neg_ratios[w]) > 0.5 and (pos_cnt.get(w, 0) + neg_cnt.get(w, 0) > 50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1719"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13a1186a0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctr = [w for w in chain.from_iterable(X_train) if w in vocab_cut]\n",
    "# ctr.values()\n",
    "plt.hist(ctr, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(57, 12690),\n",
       " (78, 9270),\n",
       " (87, 9045),\n",
       " (113, 6556),\n",
       " (114, 6551),\n",
       " (116, 6477),\n",
       " (118, 6405),\n",
       " (119, 6392),\n",
       " (138, 5301),\n",
       " (155, 4498),\n",
       " (164, 4272),\n",
       " (182, 3686),\n",
       " (185, 3628),\n",
       " (199, 3404),\n",
       " (201, 3388),\n",
       " (210, 3237),\n",
       " (222, 3113),\n",
       " (223, 3097),\n",
       " (229, 3011),\n",
       " (232, 2944),\n",
       " (233, 2944),\n",
       " (234, 2943),\n",
       " (239, 2896),\n",
       " (241, 2856),\n",
       " (249, 2727),\n",
       " (253, 2679),\n",
       " (257, 2580),\n",
       " (272, 2409),\n",
       " (275, 2382),\n",
       " (278, 2349),\n",
       " (282, 2321),\n",
       " (283, 2320),\n",
       " (286, 2307),\n",
       " (287, 2304),\n",
       " (292, 2273),\n",
       " (294, 2241),\n",
       " (299, 2210),\n",
       " (300, 2198),\n",
       " (305, 2191),\n",
       " (307, 2170),\n",
       " (320, 2091),\n",
       " (321, 2065),\n",
       " (325, 2039),\n",
       " (326, 2037),\n",
       " (336, 1931),\n",
       " (338, 1896),\n",
       " (342, 1884),\n",
       " (345, 1866),\n",
       " (352, 1830),\n",
       " (354, 1821),\n",
       " (355, 1816),\n",
       " (356, 1811),\n",
       " (357, 1809),\n",
       " (358, 1809),\n",
       " (364, 1794),\n",
       " (373, 1721),\n",
       " (379, 1698),\n",
       " (384, 1681),\n",
       " (389, 1655),\n",
       " (394, 1635),\n",
       " (404, 1594),\n",
       " (406, 1587),\n",
       " (407, 1580),\n",
       " (408, 1577),\n",
       " (424, 1515),\n",
       " (426, 1491),\n",
       " (433, 1467),\n",
       " (437, 1456),\n",
       " (439, 1447),\n",
       " (447, 1428),\n",
       " (449, 1422),\n",
       " (455, 1393),\n",
       " (456, 1386),\n",
       " (468, 1363),\n",
       " (470, 1360),\n",
       " (472, 1353),\n",
       " (478, 1323),\n",
       " (480, 1319),\n",
       " (482, 1310),\n",
       " (483, 1309),\n",
       " (495, 1279),\n",
       " (509, 1245),\n",
       " (510, 1245),\n",
       " (514, 1228),\n",
       " (527, 1200),\n",
       " (530, 1195),\n",
       " (534, 1182),\n",
       " (540, 1163),\n",
       " (542, 1157),\n",
       " (543, 1156),\n",
       " (545, 1148),\n",
       " (549, 1129),\n",
       " (558, 1109),\n",
       " (565, 1097),\n",
       " (583, 1057),\n",
       " (586, 1052),\n",
       " (589, 1049),\n",
       " (591, 1047),\n",
       " (592, 1047),\n",
       " (594, 1038),\n",
       " (595, 1034),\n",
       " (599, 1032),\n",
       " (600, 1031),\n",
       " (606, 1021),\n",
       " (607, 1020),\n",
       " (608, 1010),\n",
       " (609, 1010),\n",
       " (610, 1010),\n",
       " (615, 999),\n",
       " (616, 995),\n",
       " (621, 988),\n",
       " (628, 984),\n",
       " (629, 983),\n",
       " (639, 970),\n",
       " (640, 970),\n",
       " (642, 968),\n",
       " (647, 963),\n",
       " (649, 962),\n",
       " (659, 948),\n",
       " (660, 946),\n",
       " (672, 936),\n",
       " (684, 917),\n",
       " (691, 906),\n",
       " (693, 902),\n",
       " (696, 898),\n",
       " (705, 890),\n",
       " (706, 890),\n",
       " (709, 889),\n",
       " (710, 889),\n",
       " (716, 881),\n",
       " (718, 879),\n",
       " (723, 866),\n",
       " (727, 853),\n",
       " (728, 853),\n",
       " (731, 852),\n",
       " (733, 847),\n",
       " (735, 846),\n",
       " (737, 842),\n",
       " (748, 825),\n",
       " (753, 816),\n",
       " (755, 815),\n",
       " (762, 810),\n",
       " (776, 798),\n",
       " (777, 797),\n",
       " (778, 795),\n",
       " (781, 791),\n",
       " (782, 788),\n",
       " (785, 787),\n",
       " (787, 786),\n",
       " (790, 785),\n",
       " (793, 782),\n",
       " (798, 776),\n",
       " (802, 773),\n",
       " (804, 771),\n",
       " (805, 771),\n",
       " (806, 769),\n",
       " (807, 768),\n",
       " (811, 765),\n",
       " (815, 762),\n",
       " (821, 757),\n",
       " (829, 750),\n",
       " (830, 749),\n",
       " (833, 745),\n",
       " (835, 741),\n",
       " (837, 738),\n",
       " (839, 737),\n",
       " (841, 734),\n",
       " (845, 728),\n",
       " (851, 720),\n",
       " (862, 714),\n",
       " (863, 712),\n",
       " (864, 712),\n",
       " (865, 711),\n",
       " (867, 710),\n",
       " (870, 709),\n",
       " (876, 698),\n",
       " (880, 694),\n",
       " (892, 677),\n",
       " (894, 675),\n",
       " (897, 671),\n",
       " (901, 670),\n",
       " (903, 667),\n",
       " (906, 664),\n",
       " (913, 662),\n",
       " (921, 657),\n",
       " (926, 653),\n",
       " (927, 651),\n",
       " (933, 647),\n",
       " (936, 645),\n",
       " (939, 644),\n",
       " (947, 638),\n",
       " (950, 637),\n",
       " (954, 633),\n",
       " (955, 633),\n",
       " (961, 630),\n",
       " (964, 629),\n",
       " (965, 628),\n",
       " (969, 626),\n",
       " (975, 620),\n",
       " (976, 620),\n",
       " (984, 613),\n",
       " (986, 612),\n",
       " (991, 608),\n",
       " (995, 607),\n",
       " (996, 606),\n",
       " (999, 601),\n",
       " (1006, 596),\n",
       " (1014, 591),\n",
       " (1016, 591),\n",
       " (1023, 585),\n",
       " (1024, 585),\n",
       " (1025, 584),\n",
       " (1033, 579),\n",
       " (1034, 578),\n",
       " (1035, 577),\n",
       " (1038, 575),\n",
       " (1044, 568),\n",
       " (1047, 564),\n",
       " (1048, 563),\n",
       " (1053, 558),\n",
       " (1082, 537),\n",
       " (1084, 537),\n",
       " (1085, 537),\n",
       " (1088, 536),\n",
       " (1094, 533),\n",
       " (1095, 532),\n",
       " (1100, 530),\n",
       " (1102, 529),\n",
       " (1108, 524),\n",
       " (1117, 520),\n",
       " (1123, 518),\n",
       " (1125, 516),\n",
       " (1134, 512),\n",
       " (1135, 511),\n",
       " (1144, 507),\n",
       " (1145, 507),\n",
       " (1146, 507),\n",
       " (1149, 505),\n",
       " (1154, 503),\n",
       " (1156, 502),\n",
       " (1157, 502),\n",
       " (1158, 501),\n",
       " (1159, 500),\n",
       " (1173, 491),\n",
       " (1178, 489),\n",
       " (1179, 489),\n",
       " (1180, 488),\n",
       " (1188, 486),\n",
       " (1190, 485),\n",
       " (1191, 485),\n",
       " (1196, 483),\n",
       " (1198, 482),\n",
       " (1199, 481),\n",
       " (1201, 481),\n",
       " (1209, 477),\n",
       " (1214, 472),\n",
       " (1216, 471),\n",
       " (1218, 471),\n",
       " (1220, 470),\n",
       " (1222, 470),\n",
       " (1223, 469),\n",
       " (1224, 469),\n",
       " (1226, 469),\n",
       " (1229, 467),\n",
       " (1231, 467),\n",
       " (1235, 465),\n",
       " (1236, 465),\n",
       " (1238, 464),\n",
       " (1240, 462),\n",
       " (1242, 461),\n",
       " (1243, 460),\n",
       " (1244, 460),\n",
       " (1249, 456),\n",
       " (1252, 455),\n",
       " (1254, 454),\n",
       " (1258, 452),\n",
       " (1259, 452),\n",
       " (1262, 451),\n",
       " (1265, 450),\n",
       " (1275, 446),\n",
       " (1281, 442),\n",
       " (1282, 441),\n",
       " (1286, 439),\n",
       " (1289, 438),\n",
       " (1293, 436),\n",
       " (1297, 435),\n",
       " (1298, 435),\n",
       " (1299, 435),\n",
       " (1300, 434),\n",
       " (1301, 434),\n",
       " (1302, 433),\n",
       " (1306, 432),\n",
       " (1307, 432),\n",
       " (1308, 431),\n",
       " (1311, 428),\n",
       " (1315, 426),\n",
       " (1318, 425),\n",
       " (1322, 424),\n",
       " (1323, 424),\n",
       " (1324, 423),\n",
       " (1326, 423),\n",
       " (1332, 421),\n",
       " (1334, 420),\n",
       " (1335, 420),\n",
       " (1338, 418),\n",
       " (1339, 418),\n",
       " (1342, 416),\n",
       " (1344, 416),\n",
       " (1349, 416),\n",
       " (1350, 415),\n",
       " (1356, 414),\n",
       " (1359, 413),\n",
       " (1362, 411),\n",
       " (1365, 411),\n",
       " (1380, 407),\n",
       " (1382, 406),\n",
       " (1383, 406),\n",
       " (1387, 404),\n",
       " (1388, 404),\n",
       " (1390, 404),\n",
       " (1399, 401),\n",
       " (1400, 401),\n",
       " (1402, 401),\n",
       " (1407, 398),\n",
       " (1408, 397),\n",
       " (1412, 395),\n",
       " (1414, 395),\n",
       " (1415, 395),\n",
       " (1417, 394),\n",
       " (1429, 391),\n",
       " (1438, 388),\n",
       " (1439, 388),\n",
       " (1441, 387),\n",
       " (1444, 385),\n",
       " (1450, 383),\n",
       " (1456, 380),\n",
       " (1458, 380),\n",
       " (1469, 377),\n",
       " (1476, 374),\n",
       " (1480, 372),\n",
       " (1483, 371),\n",
       " (1484, 370),\n",
       " (1485, 370),\n",
       " (1486, 370),\n",
       " (1488, 369),\n",
       " (1490, 369),\n",
       " (1497, 367),\n",
       " (1499, 366),\n",
       " (1501, 366),\n",
       " (1502, 366),\n",
       " (1503, 365),\n",
       " (1505, 365),\n",
       " (1509, 364),\n",
       " (1511, 364),\n",
       " (1512, 363),\n",
       " (1519, 361),\n",
       " (1521, 361),\n",
       " (1523, 360),\n",
       " (1525, 360),\n",
       " (1526, 360),\n",
       " (1528, 359),\n",
       " (1529, 359),\n",
       " (1536, 359),\n",
       " (1539, 358),\n",
       " (1545, 356),\n",
       " (1548, 355),\n",
       " (1552, 353),\n",
       " (1555, 352),\n",
       " (1558, 351),\n",
       " (1560, 351),\n",
       " (1562, 350),\n",
       " (1568, 350),\n",
       " (1574, 348),\n",
       " (1576, 348),\n",
       " (1579, 347),\n",
       " (1580, 346),\n",
       " (1581, 346),\n",
       " (1584, 345),\n",
       " (1589, 343),\n",
       " (1591, 342),\n",
       " (1596, 342),\n",
       " (1603, 339),\n",
       " (1607, 338),\n",
       " (1608, 337),\n",
       " (1610, 337),\n",
       " (1611, 337),\n",
       " (1620, 335),\n",
       " (1628, 332),\n",
       " (1639, 329),\n",
       " (1640, 329),\n",
       " (1641, 329),\n",
       " (1642, 329),\n",
       " (1648, 328),\n",
       " (1653, 326),\n",
       " (1656, 326),\n",
       " (1662, 325),\n",
       " (1664, 325),\n",
       " (1666, 325),\n",
       " (1669, 324),\n",
       " (1674, 323),\n",
       " (1675, 323),\n",
       " (1677, 323),\n",
       " (1681, 322),\n",
       " (1683, 321),\n",
       " (1685, 321),\n",
       " (1689, 320),\n",
       " (1690, 320),\n",
       " (1694, 319),\n",
       " (1697, 318),\n",
       " (1710, 315),\n",
       " (1711, 315),\n",
       " (1712, 315),\n",
       " (1715, 315),\n",
       " (1731, 310),\n",
       " (1732, 310),\n",
       " (1738, 309),\n",
       " (1739, 309),\n",
       " (1740, 308),\n",
       " (1742, 308),\n",
       " (1744, 307),\n",
       " (1746, 307),\n",
       " (1749, 307),\n",
       " (1751, 306),\n",
       " (1753, 306),\n",
       " (1755, 305),\n",
       " (1758, 304),\n",
       " (1762, 304),\n",
       " (1767, 302),\n",
       " (1768, 302),\n",
       " (1770, 302),\n",
       " (1771, 301),\n",
       " (1777, 300),\n",
       " (1780, 299),\n",
       " (1785, 298),\n",
       " (1789, 297),\n",
       " (1790, 297),\n",
       " (1791, 297),\n",
       " (1792, 296),\n",
       " (1797, 295),\n",
       " (1798, 295),\n",
       " (1800, 295),\n",
       " (1805, 293),\n",
       " (1807, 293),\n",
       " (1808, 293),\n",
       " (1809, 293),\n",
       " (1812, 292),\n",
       " (1820, 290),\n",
       " (1821, 290),\n",
       " (1823, 290),\n",
       " (1826, 289),\n",
       " (1827, 289),\n",
       " (1829, 289),\n",
       " (1831, 289),\n",
       " (1833, 287),\n",
       " (1835, 287),\n",
       " (1837, 287),\n",
       " (1843, 285),\n",
       " (1846, 285),\n",
       " (1850, 285),\n",
       " (1852, 284),\n",
       " (1854, 284),\n",
       " (1856, 283),\n",
       " (1858, 283),\n",
       " (1862, 283),\n",
       " (1863, 283),\n",
       " (1870, 281),\n",
       " (1872, 281),\n",
       " (1878, 280),\n",
       " (1879, 279),\n",
       " (1881, 278),\n",
       " (1882, 278),\n",
       " (1883, 278),\n",
       " (1885, 278),\n",
       " (1891, 277),\n",
       " (1892, 277),\n",
       " (1894, 276),\n",
       " (1895, 276),\n",
       " (1896, 275),\n",
       " (1897, 275),\n",
       " (1898, 275),\n",
       " (1904, 274),\n",
       " (1905, 274),\n",
       " (1907, 274),\n",
       " (1908, 274),\n",
       " (1916, 273),\n",
       " (1917, 273),\n",
       " (1920, 273),\n",
       " (1922, 272),\n",
       " (1924, 272),\n",
       " (1930, 271),\n",
       " (1938, 271),\n",
       " (1939, 271),\n",
       " (1940, 271),\n",
       " (1946, 269),\n",
       " (1948, 269),\n",
       " (1951, 268),\n",
       " (1954, 267),\n",
       " (1957, 267),\n",
       " (1960, 266),\n",
       " (1965, 266),\n",
       " (1971, 265),\n",
       " (1977, 264),\n",
       " (1980, 263),\n",
       " (1985, 263),\n",
       " (1986, 262),\n",
       " (1987, 262),\n",
       " (1990, 262),\n",
       " (1999, 261),\n",
       " (2000, 261),\n",
       " (2004, 261),\n",
       " (2005, 260),\n",
       " (2009, 259),\n",
       " (2012, 259),\n",
       " (2016, 259),\n",
       " (2017, 259),\n",
       " (2021, 258),\n",
       " (2023, 258),\n",
       " (2032, 257),\n",
       " (2033, 257),\n",
       " (2035, 256),\n",
       " (2038, 256),\n",
       " (2040, 256),\n",
       " (2043, 255),\n",
       " (2044, 255),\n",
       " (2050, 254),\n",
       " (2052, 254),\n",
       " (2053, 254),\n",
       " (2056, 253),\n",
       " (2058, 253),\n",
       " (2060, 253),\n",
       " (2062, 252),\n",
       " (2067, 251),\n",
       " (2075, 250),\n",
       " (2076, 250),\n",
       " (2077, 250),\n",
       " (2079, 250),\n",
       " (2080, 250),\n",
       " (2088, 249),\n",
       " (2091, 248),\n",
       " (2093, 248),\n",
       " (2095, 248),\n",
       " (2098, 247),\n",
       " (2104, 247),\n",
       " (2105, 247),\n",
       " (2109, 246),\n",
       " (2112, 246),\n",
       " (2115, 246),\n",
       " (2118, 246),\n",
       " (2119, 246),\n",
       " (2120, 246),\n",
       " (2124, 245),\n",
       " (2126, 245),\n",
       " (2128, 244),\n",
       " (2130, 244),\n",
       " (2135, 242),\n",
       " (2136, 242),\n",
       " (2137, 242),\n",
       " (2139, 242),\n",
       " (2141, 241),\n",
       " (2146, 240),\n",
       " (2147, 240),\n",
       " (2148, 240),\n",
       " (2149, 240),\n",
       " (2150, 240),\n",
       " (2151, 239),\n",
       " (2152, 239),\n",
       " (2158, 238),\n",
       " (2165, 237),\n",
       " (2166, 237),\n",
       " (2168, 237),\n",
       " (2169, 237),\n",
       " (2172, 237),\n",
       " (2175, 237),\n",
       " (2180, 237),\n",
       " (2182, 236),\n",
       " (2184, 236),\n",
       " (2185, 236),\n",
       " (2187, 236),\n",
       " (2188, 236),\n",
       " (2197, 235),\n",
       " (2198, 235),\n",
       " (2203, 234),\n",
       " (2204, 234),\n",
       " (2205, 234),\n",
       " (2208, 233),\n",
       " (2211, 233),\n",
       " (2221, 231),\n",
       " (2227, 231),\n",
       " (2233, 230),\n",
       " (2234, 230),\n",
       " (2235, 229),\n",
       " (2237, 229),\n",
       " (2241, 229),\n",
       " (2245, 229),\n",
       " (2247, 229),\n",
       " (2248, 229),\n",
       " (2252, 228),\n",
       " (2254, 228),\n",
       " (2255, 228),\n",
       " (2259, 227),\n",
       " (2262, 227),\n",
       " (2264, 227),\n",
       " (2265, 226),\n",
       " (2266, 226),\n",
       " (2267, 226),\n",
       " (2268, 226),\n",
       " (2269, 226),\n",
       " (2270, 226),\n",
       " (2271, 226),\n",
       " (2272, 226),\n",
       " (2273, 225),\n",
       " (2274, 225),\n",
       " (2281, 224),\n",
       " (2284, 224),\n",
       " (2286, 224),\n",
       " (2287, 224),\n",
       " (2288, 224),\n",
       " (2289, 224),\n",
       " (2291, 224),\n",
       " (2299, 223),\n",
       " (2300, 222),\n",
       " (2301, 222),\n",
       " (2305, 222),\n",
       " (2306, 222),\n",
       " (2307, 222),\n",
       " (2313, 221),\n",
       " (2315, 221),\n",
       " (2316, 221),\n",
       " (2317, 221),\n",
       " (2320, 220),\n",
       " (2321, 220),\n",
       " (2323, 220),\n",
       " (2325, 219),\n",
       " (2327, 219),\n",
       " (2329, 218),\n",
       " (2332, 218),\n",
       " (2337, 217),\n",
       " (2339, 217),\n",
       " (2342, 216),\n",
       " (2345, 216),\n",
       " (2346, 216),\n",
       " (2349, 215),\n",
       " (2352, 215),\n",
       " (2353, 215),\n",
       " (2354, 215),\n",
       " (2355, 215),\n",
       " (2356, 214),\n",
       " (2357, 214),\n",
       " (2359, 214),\n",
       " (2361, 214),\n",
       " (2364, 214),\n",
       " (2366, 214),\n",
       " (2370, 213),\n",
       " (2374, 213),\n",
       " (2376, 212),\n",
       " (2379, 212),\n",
       " (2383, 212),\n",
       " (2384, 212),\n",
       " (2385, 212),\n",
       " (2386, 211),\n",
       " (2390, 210),\n",
       " (2392, 210),\n",
       " (2393, 210),\n",
       " (2394, 210),\n",
       " (2398, 210),\n",
       " (2399, 210),\n",
       " (2402, 210),\n",
       " (2403, 210),\n",
       " (2406, 209),\n",
       " (2419, 208),\n",
       " (2426, 207),\n",
       " (2427, 207),\n",
       " (2428, 206),\n",
       " (2430, 206),\n",
       " (2434, 206),\n",
       " (2441, 205),\n",
       " (2442, 205),\n",
       " (2443, 205),\n",
       " (2446, 205),\n",
       " (2447, 204),\n",
       " (2451, 204),\n",
       " (2455, 204),\n",
       " (2456, 204),\n",
       " (2458, 203),\n",
       " (2459, 203),\n",
       " (2463, 203),\n",
       " (2470, 202),\n",
       " (2474, 201),\n",
       " (2480, 201),\n",
       " (2481, 201),\n",
       " (2483, 201),\n",
       " (2488, 200),\n",
       " (2490, 200),\n",
       " (2493, 200),\n",
       " (2500, 199),\n",
       " (2501, 199),\n",
       " (2502, 199),\n",
       " (2503, 199),\n",
       " (2510, 198),\n",
       " (2511, 198),\n",
       " (2513, 198),\n",
       " (2517, 197),\n",
       " (2522, 197),\n",
       " (2525, 196),\n",
       " (2526, 196),\n",
       " (2528, 195),\n",
       " (2529, 195),\n",
       " (2530, 195),\n",
       " (2532, 195),\n",
       " (2533, 195),\n",
       " (2535, 195),\n",
       " (2538, 195),\n",
       " (2539, 195),\n",
       " (2542, 194),\n",
       " (2545, 194),\n",
       " (2547, 194),\n",
       " (2549, 194),\n",
       " (2560, 192),\n",
       " (2562, 192),\n",
       " (2563, 192),\n",
       " (2565, 192),\n",
       " (2566, 192),\n",
       " (2570, 191),\n",
       " (2575, 191),\n",
       " (2576, 191),\n",
       " (2579, 190),\n",
       " (2582, 190),\n",
       " (2585, 190),\n",
       " (2588, 190),\n",
       " (2592, 189),\n",
       " (2593, 189),\n",
       " (2597, 189),\n",
       " (2602, 189),\n",
       " (2603, 189),\n",
       " (2606, 188),\n",
       " (2608, 188),\n",
       " (2609, 188),\n",
       " (2610, 188),\n",
       " (2612, 188),\n",
       " (2616, 188),\n",
       " (2619, 187),\n",
       " (2620, 187),\n",
       " (2622, 187),\n",
       " (2624, 187),\n",
       " (2626, 187),\n",
       " (2627, 187),\n",
       " (2631, 186),\n",
       " (2634, 186),\n",
       " (2635, 186),\n",
       " (2641, 185),\n",
       " (2648, 184),\n",
       " (2649, 184),\n",
       " (2652, 184),\n",
       " (2653, 184),\n",
       " (2659, 183),\n",
       " (2665, 183),\n",
       " (2666, 183),\n",
       " (2671, 182),\n",
       " (2672, 182),\n",
       " (2675, 182),\n",
       " (2677, 182),\n",
       " (2679, 182),\n",
       " (2680, 182),\n",
       " (2683, 182),\n",
       " (2686, 181),\n",
       " (2688, 181),\n",
       " (2696, 181),\n",
       " (2697, 181),\n",
       " (2698, 181),\n",
       " (2700, 180),\n",
       " (2706, 180),\n",
       " (2710, 179),\n",
       " (2711, 179),\n",
       " (2713, 179),\n",
       " (2714, 179),\n",
       " (2720, 179),\n",
       " (2721, 178),\n",
       " (2725, 178),\n",
       " (2726, 178),\n",
       " (2728, 178),\n",
       " (2729, 178),\n",
       " (2732, 178),\n",
       " (2733, 178),\n",
       " (2734, 178),\n",
       " (2735, 178),\n",
       " (2737, 178),\n",
       " (2742, 177),\n",
       " (2743, 177),\n",
       " (2744, 177),\n",
       " (2746, 177),\n",
       " (2749, 177),\n",
       " (2750, 177),\n",
       " (2753, 177),\n",
       " (2755, 177),\n",
       " (2756, 176),\n",
       " (2757, 176),\n",
       " (2758, 176),\n",
       " (2759, 176),\n",
       " (2760, 176),\n",
       " (2761, 176),\n",
       " (2767, 176),\n",
       " (2769, 175),\n",
       " (2774, 175),\n",
       " (2775, 175),\n",
       " (2776, 175),\n",
       " (2777, 175),\n",
       " (2780, 175),\n",
       " (2781, 175),\n",
       " (2782, 175),\n",
       " (2791, 174),\n",
       " (2793, 174),\n",
       " (2797, 174),\n",
       " (2798, 174),\n",
       " (2801, 173),\n",
       " (2802, 173),\n",
       " (2803, 173),\n",
       " (2806, 173),\n",
       " (2807, 173),\n",
       " (2811, 173),\n",
       " (2812, 173),\n",
       " (2814, 173),\n",
       " (2815, 173),\n",
       " (2816, 172),\n",
       " (2821, 172),\n",
       " (2823, 172),\n",
       " (2825, 172),\n",
       " (2830, 171),\n",
       " (2832, 171),\n",
       " (2834, 171),\n",
       " (2835, 171),\n",
       " (2842, 170),\n",
       " (2846, 170),\n",
       " (2847, 170),\n",
       " (2852, 169),\n",
       " (2853, 169),\n",
       " (2856, 169),\n",
       " (2858, 169),\n",
       " (2860, 169),\n",
       " (2863, 169),\n",
       " (2869, 168),\n",
       " (2874, 168),\n",
       " (2877, 168),\n",
       " (2879, 167),\n",
       " (2880, 167),\n",
       " (2882, 167),\n",
       " (2889, 167),\n",
       " (2890, 167),\n",
       " (2891, 166),\n",
       " (2894, 166),\n",
       " (2902, 166),\n",
       " (2905, 166),\n",
       " (2907, 165),\n",
       " (2908, 165),\n",
       " (2912, 165),\n",
       " (2914, 165),\n",
       " (2916, 165),\n",
       " (2919, 164),\n",
       " (2925, 164),\n",
       " (2927, 164),\n",
       " (2930, 164),\n",
       " (2931, 164),\n",
       " (2933, 164),\n",
       " (2934, 164),\n",
       " (2938, 163),\n",
       " (2940, 163),\n",
       " (2941, 163),\n",
       " (2942, 163),\n",
       " (2952, 163),\n",
       " (2953, 163),\n",
       " (2955, 162),\n",
       " (2956, 162),\n",
       " (2957, 162),\n",
       " (2963, 162),\n",
       " (2965, 161),\n",
       " (2972, 161),\n",
       " (2975, 161),\n",
       " (2979, 160),\n",
       " (2983, 160),\n",
       " (2987, 160),\n",
       " (2996, 159),\n",
       " (2998, 159),\n",
       " (3000, 158),\n",
       " (3001, 158),\n",
       " (3002, 158),\n",
       " (3005, 158),\n",
       " (3006, 158),\n",
       " (3007, 158),\n",
       " (3008, 158),\n",
       " (3010, 158),\n",
       " (3012, 157),\n",
       " (3013, 157),\n",
       " (3014, 157),\n",
       " (3015, 157),\n",
       " (3018, 157),\n",
       " (3020, 157),\n",
       " (3029, 156),\n",
       " (3030, 156),\n",
       " (3032, 156),\n",
       " (3033, 156),\n",
       " (3036, 156),\n",
       " (3037, 156),\n",
       " (3038, 156),\n",
       " (3040, 155),\n",
       " (3042, 155),\n",
       " (3043, 155),\n",
       " (3045, 155),\n",
       " (3046, 155),\n",
       " (3047, 155),\n",
       " (3049, 155),\n",
       " (3051, 155),\n",
       " (3052, 155),\n",
       " (3055, 154),\n",
       " (3056, 154),\n",
       " (3058, 154),\n",
       " (3059, 154),\n",
       " (3060, 154),\n",
       " (3061, 154),\n",
       " (3065, 154),\n",
       " (3069, 154),\n",
       " (3081, 153),\n",
       " (3082, 153),\n",
       " (3083, 153),\n",
       " (3091, 152),\n",
       " (3093, 152),\n",
       " (3094, 152),\n",
       " (3096, 152),\n",
       " (3100, 151),\n",
       " (3101, 151),\n",
       " (3104, 151),\n",
       " (3106, 151),\n",
       " (3107, 151),\n",
       " (3110, 151),\n",
       " (3121, 150),\n",
       " (3124, 150),\n",
       " (3125, 150),\n",
       " (3127, 150),\n",
       " (3131, 150),\n",
       " (3132, 149),\n",
       " (3133, 149),\n",
       " (3134, 149),\n",
       " (3135, 149),\n",
       " (3136, 149),\n",
       " (3137, 149),\n",
       " (3140, 149),\n",
       " (3142, 149),\n",
       " (3143, 149),\n",
       " (3144, 149),\n",
       " (3147, 149),\n",
       " (3151, 148),\n",
       " (3152, 148),\n",
       " (3153, 148),\n",
       " (3158, 148),\n",
       " (3160, 148),\n",
       " (3161, 148),\n",
       " (3163, 147),\n",
       " (3164, 147),\n",
       " (3166, 147),\n",
       " (3169, 147),\n",
       " (3170, 147),\n",
       " (3173, 146),\n",
       " (3174, 146),\n",
       " (3175, 146),\n",
       " (3177, 146),\n",
       " (3178, 146),\n",
       " (3179, 146),\n",
       " (3180, 146),\n",
       " (3181, 146),\n",
       " (3184, 146),\n",
       " (3189, 145),\n",
       " (3192, 145),\n",
       " (3193, 145),\n",
       " (3197, 145),\n",
       " (3199, 144),\n",
       " (3202, 144),\n",
       " (3203, 144),\n",
       " (3204, 144),\n",
       " (3205, 144),\n",
       " (3206, 144),\n",
       " (3209, 144),\n",
       " (3210, 144),\n",
       " (3213, 143),\n",
       " (3214, 143),\n",
       " (3216, 143),\n",
       " (3221, 143),\n",
       " (3222, 143),\n",
       " (3223, 143),\n",
       " (3226, 143),\n",
       " (3228, 143),\n",
       " (3237, 142),\n",
       " (3240, 142),\n",
       " (3245, 142),\n",
       " (3253, 141),\n",
       " (3252, 141),\n",
       " (3257, 141),\n",
       " (3262, 141),\n",
       " (3265, 141),\n",
       " (3268, 140),\n",
       " (3270, 140),\n",
       " (3272, 140),\n",
       " (3273, 140),\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13a11e390>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_neg_ratios_cut = Counter()\n",
    "for w in vocab_cut:\n",
    "    pos_neg_ratios_cut[w] = math.log(pos_cnt.get(w, 1) / neg_cnt.get(w, 1))\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(pos_neg_ratios_cut.values(), 100)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leave just words from reduced vocabulary\n",
    "X_train = [[w for w in review if w in vocab_cut]for review in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike our Bag-of-Words approach, where we simply summarized the counts of each word in a document, this representation essentially retains the entire sequence of words (minus punctuation, stopwords, etc.). This is critical for RNNs to function. But it also means that now the features can be of different lengths!\n",
    "\n",
    "#### Question: Variable length reviews\n",
    "\n",
    "What is the maximum review length (in terms of number of words) in the training set? What is the minimum?\n",
    "\n",
    "#### Answer:\n",
    "\n",
    "Maximum 2494 words\n",
    "Minimum 11\n",
    "\n",
    "\n",
    "### TODO: Pad sequences\n",
    "\n",
    "In order to feed this data into your RNN, all input documents must have the same length. Let's limit the maximum review length to `max_words` by truncating longer reviews and padding shorter reviews with a null value (0). You can accomplish this easily using the [`pad_sequences()`](https://keras.io/preprocessing/sequence/#pad_sequences) function in Keras. For now, set `max_words` to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Set the maximum number of words per document (for both training and testing)\n",
    "max_words = 500\n",
    "\n",
    "# TODO: Pad sequences in X_train and X_test\n",
    "X_train_pad = sequence.pad_sequences(X_train, maxlen=max_words, padding='pre', truncating='post')\n",
    "X_test_pad = sequence.pad_sequences(X_test, maxlen=max_words, padding='pre', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,  530,  480,  336,\n",
       "        447, 1920,   87,  530,  480, 3785, 1415,  407, 3766,  723,  530,\n",
       "        480, 1334,  283, 4472,  113], dtype=int32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Design an RNN model for sentiment analysis\n",
    "\n",
    "Build your model architecture in the code cell below. We have imported some layers from Keras that you might need but feel free to use any other layers / transformations you like.\n",
    "\n",
    "Remember that your input is a sequence of words (technically, integer word IDs) of maximum length = `max_words`, and your output is a binary sentiment label (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 242,561\n",
      "Trainable params: 242,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# TODO: Design your model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, 32, input_length=max_words))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Architecture and parameters\n",
    "\n",
    "Briefly describe your neural net architecture. How many model parameters does it have that need to be trained?\n",
    "\n",
    "#### Answer:\n",
    "\n",
    "...\n",
    "\n",
    "### TODO: Train and evaluate your model\n",
    "\n",
    "Now you are ready to train your model. In Keras world, you first need to _compile_ your model by specifying the loss function and optimizer you want to use while training, as well as any evaluation metrics you'd like to measure. Specify the approprate parameters, including at least one metric `'accuracy'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile your model, specifying a loss function, optimizer, and metrics\n",
    "model.compile('adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once compiled, you can kick off the training process. There are two important training parameters that you have to specify - **batch size** and **number of training epochs**, which together with your model architecture determine the total training time.\n",
    "\n",
    "Training may take a while, so grab a cup of coffee, or better, go for a hike! If possible, consider using a GPU, as a single training run can take several hours on a CPU.\n",
    "\n",
    "> **Tip**: You can split off a small portion of the training set to be used for validation during training. This will help monitor the training process and identify potential overfitting. You can supply a validation set to `model.fit()` using its `validation_data` parameter, or just specify `validation_split` - a fraction of the training data for Keras to set aside for this purpose (typically 5-10%). Validation metrics are evaluated once at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pad = to_categorical(y_train, num_classes=2)\n",
    "y_test_pad = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/hmm-tagger/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23250 samples, validate on 1750 samples\n",
      "Epoch 1/5\n",
      "23250/23250 [==============================] - 224s 10ms/step - loss: 0.1784 - accuracy: 0.7847 - val_loss: 0.1110 - val_accuracy: 0.8520\n",
      "Epoch 2/5\n",
      "23250/23250 [==============================] - 221s 10ms/step - loss: 0.0890 - accuracy: 0.8800 - val_loss: 0.0879 - val_accuracy: 0.8857\n",
      "Epoch 3/5\n",
      "23250/23250 [==============================] - 215s 9ms/step - loss: 0.0764 - accuracy: 0.8989 - val_loss: 0.0854 - val_accuracy: 0.8931\n",
      "Epoch 4/5\n",
      "23250/23250 [==============================] - 216s 9ms/step - loss: 0.0723 - accuracy: 0.9047 - val_loss: 0.0865 - val_accuracy: 0.8880\n",
      "Epoch 5/5\n",
      "23250/23250 [==============================] - 221s 10ms/step - loss: 0.0690 - accuracy: 0.9105 - val_loss: 0.0856 - val_accuracy: 0.8903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x137e01f98>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Specify training parameters: batch size and number of epochs\n",
    "batch_size = 256\n",
    "num_epochs = 5\n",
    "\n",
    "# TODO(optional): Reserve/specify some training data for validation (not to be used for training)\n",
    "\n",
    "# TODO: Train your model\n",
    "model.fit(x=X_train_pad, y=y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Validation accuracy: \n",
    "\n",
    "0.8474 (full vocabulary with arch: Emb->LSTM(128)->Dense(1))\n",
    "\n",
    "0.8903 (reduced vocab - min 50 occurences of word, above 0.5 ratio in pos_neg_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model, so that you can quickly load it in future (and perhaps resume training)\n",
    "model_file = \"rnn_model.h5\"  # HDF5 file\n",
    "model.save(os.path.join(cache_dir, model_file))\n",
    "\n",
    "# Later you can load it using keras.models.load_model()\n",
    "#from keras.models import load_model\n",
    "#model = load_model(os.path.join(cache_dir, model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have trained your model, it's time to see how well it performs on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7774400115013123\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model on the test set\n",
    "scores = model.evaluate(X_test_pad, y_test, verbose=0)  # returns loss and other metrics specified in model.compile()\n",
    "print(\"Test accuracy:\", scores[1])  # scores[1] should correspond to accuracy if you passed in metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try just simple dense model\n",
    "model_dense = Sequential()\n",
    "# model_dense.add(Embedding(vocabulary_size, 32))\n",
    "model_dense.add(Dense(32, activation='relu'))\n",
    "model_dense.add(Dropout(0.3))\n",
    "model_dense.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# print(model_dense.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(X):\n",
    "    hot = np.zeros((len(X), vocabulary_size))\n",
    "    for i, xi in enumerate(X):\n",
    "        hot[i][xi] = 1\n",
    "    return hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hot = one_hot(X_train)\n",
    "X_test_hot = one_hot(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23250 samples, validate on 1750 samples\n",
      "Epoch 1/5\n",
      "23250/23250 [==============================] - 1s 54us/step - loss: 0.1479 - accuracy: 0.8347 - val_loss: 0.1003 - val_accuracy: 0.8766\n",
      "Epoch 2/5\n",
      "23250/23250 [==============================] - 1s 39us/step - loss: 0.0907 - accuracy: 0.8852 - val_loss: 0.0889 - val_accuracy: 0.8863\n",
      "Epoch 3/5\n",
      "23250/23250 [==============================] - 1s 40us/step - loss: 0.0813 - accuracy: 0.8946 - val_loss: 0.0866 - val_accuracy: 0.8880\n",
      "Epoch 4/5\n",
      "23250/23250 [==============================] - 1s 38us/step - loss: 0.0771 - accuracy: 0.9003 - val_loss: 0.0865 - val_accuracy: 0.8840\n",
      "Epoch 5/5\n",
      "23250/23250 [==============================] - 1s 40us/step - loss: 0.0738 - accuracy: 0.9040 - val_loss: 0.0870 - val_accuracy: 0.8863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x137b09a20>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dense.fit(x=X_train_hot, y=y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8708000183105469\n"
     ]
    }
   ],
   "source": [
    "scores = model_dense.evaluate(X_test_hot, y_test, verbose=0)  # returns loss and other metrics specified in model.compile()\n",
    "print(\"Test accuracy:\", scores[1])  # scores[1] should correspond to accuracy if you passed in metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Comparing RNNs and Traditional Methods\n",
    "\n",
    "How well does your RNN model perform compared to the BoW + Gradient-Boosted Decision Trees?\n",
    "\n",
    "#### Answer:\n",
    "\n",
    "...\n",
    "\n",
    "## Extensions\n",
    "\n",
    "There are several ways in which you can build upon this notebook. Each comes with its set of challenges, but can be a rewarding experience.\n",
    "\n",
    "- The first thing is to try and improve the accuracy of your model by experimenting with different architectures, layers and parameters. How good can you get without taking prohibitively long to train? How do you prevent overfitting?\n",
    "\n",
    "- Then, you may want to deploy your model as a mobile app or web service. What do you need to do in order to package your model for such deployment? How would you accept a new review, convert it into a form suitable for your model, and perform the actual prediction? (Note that the same environment you used during training may not be available.)\n",
    "\n",
    "- One simplification we made in this notebook is to limit the task to binary classification. The dataset actually includes a more fine-grained review rating that is indicated in each review's filename (which is of the form `<[id]_[rating].txt>` where `[id]` is a unique identifier and `[rating]` is on a scale of 1-10; note that neutral reviews > 4 or < 7 have been excluded). How would you modify the notebook to perform regression on the review ratings? In what situations is regression more useful than classification, and vice-versa?\n",
    "\n",
    "Whatever direction you take, make sure to share your results and learnings with your peers, through blogs, discussions and participating in online competitions. This is also a great way to become more visible to potential employers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
